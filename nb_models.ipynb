{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe4163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, classification_report, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed9c43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "original = pd.read_csv(\"bank-full.csv\", sep=\";\")\n",
    "original['y'] = original['y'].apply(lambda x: 1 if x==\"yes\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287dcef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Findings\n",
    "\n",
    "- \"day\" can get encoded or transformed in some way since its not ratio data.  \n",
    "- \"pdays\" has \"-1\" for missing data, otherwise is useful ratio data. Often people get called around quarter, half, full year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11815232",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0dd449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert day column to str so we will get target encoding as below\n",
    "\n",
    "train['day'] = train['day'].astype(str)\n",
    "original['day'] = original['day'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb516856",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd44b07b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6044c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Concatenate original + synthetic\n",
    "train = pd.concat([train, original], ignore_index=True)\n",
    "\n",
    "# Step 2: Categorical columns\n",
    "cat_cols = original.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Step 3: Compute target means from original, and map to full train\n",
    "for col in cat_cols:\n",
    "    te_map = original.groupby(col)['y'].mean().to_dict()  # mean target per category\n",
    "    train[col + \"_mean\"] = train[col].map(te_map)         # apply to full train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c0a626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for pdays = -1\n",
    "\n",
    "train['pdays_none'] = train['pdays'] == -1\n",
    "\n",
    "\n",
    "train['pdays'] = train['pdays'].apply(lambda x: np.nan if x == -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b280514",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train.drop(columns=['y','id']), train['y'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0249d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5e2f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected categorical features: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'day', 'month', 'poutcome']\n"
     ]
    }
   ],
   "source": [
    "# Assuming x_train is your DataFrame of features\n",
    "categorical_features_names = x_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Make sure 'remainder__MSZoning' is in this list. It should be if its dtype is object.\n",
    "print(\"Detected categorical features:\", categorical_features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ad6676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded best parameters:\n",
      "{'depth': 7, 'learning_rate': 0.16242304317665213, 'l2_leaf_reg': 9.784139225596583, 'iterations': 991, 'subsample': 0.6576101811374836}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import optuna\n",
    "\n",
    "# Load the best parameters from the saved file\n",
    "try:\n",
    "    with open(\"models/optuna_cat1.json\", \"r\") as f:\n",
    "        best_params = json.load(f)\n",
    "    print(\"Successfully loaded best parameters:\")\n",
    "    print(best_params)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'best_params.json' was not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4c9ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4431566\ttotal: 786ms\tremaining: 12m 58s\n",
      "1:\tlearn: 0.3304450\ttotal: 1.53s\tremaining: 12m 38s\n",
      "2:\tlearn: 0.2721577\ttotal: 2.18s\tremaining: 11m 59s\n",
      "3:\tlearn: 0.2375044\ttotal: 2.83s\tremaining: 11m 39s\n",
      "4:\tlearn: 0.2197653\ttotal: 3.47s\tremaining: 11m 23s\n",
      "5:\tlearn: 0.2091893\ttotal: 4.07s\tremaining: 11m 7s\n",
      "6:\tlearn: 0.2012592\ttotal: 4.71s\tremaining: 11m 1s\n",
      "7:\tlearn: 0.1953461\ttotal: 5.36s\tremaining: 10m 58s\n",
      "8:\tlearn: 0.1906391\ttotal: 6.01s\tremaining: 10m 56s\n",
      "9:\tlearn: 0.1877195\ttotal: 6.67s\tremaining: 10m 54s\n",
      "10:\tlearn: 0.1855219\ttotal: 7.32s\tremaining: 10m 52s\n",
      "11:\tlearn: 0.1828321\ttotal: 8s\tremaining: 10m 52s\n",
      "12:\tlearn: 0.1783854\ttotal: 8.59s\tremaining: 10m 46s\n",
      "13:\tlearn: 0.1772225\ttotal: 9.26s\tremaining: 10m 46s\n",
      "14:\tlearn: 0.1762571\ttotal: 9.9s\tremaining: 10m 44s\n",
      "15:\tlearn: 0.1749419\ttotal: 10.5s\tremaining: 10m 39s\n",
      "16:\tlearn: 0.1723260\ttotal: 11.1s\tremaining: 10m 34s\n",
      "17:\tlearn: 0.1715459\ttotal: 11.7s\tremaining: 10m 29s\n",
      "18:\tlearn: 0.1708356\ttotal: 12.2s\tremaining: 10m 25s\n",
      "19:\tlearn: 0.1702498\ttotal: 12.8s\tremaining: 10m 21s\n",
      "20:\tlearn: 0.1687826\ttotal: 13.4s\tremaining: 10m 16s\n",
      "21:\tlearn: 0.1683043\ttotal: 14s\tremaining: 10m 14s\n",
      "22:\tlearn: 0.1671872\ttotal: 14.5s\tremaining: 10m 8s\n",
      "23:\tlearn: 0.1667552\ttotal: 15s\tremaining: 10m 5s\n",
      "24:\tlearn: 0.1657550\ttotal: 15.6s\tremaining: 10m 2s\n",
      "25:\tlearn: 0.1647807\ttotal: 16.1s\tremaining: 9m 57s\n",
      "26:\tlearn: 0.1642471\ttotal: 16.8s\tremaining: 10m\n",
      "27:\tlearn: 0.1637815\ttotal: 17.4s\tremaining: 9m 56s\n",
      "28:\tlearn: 0.1632642\ttotal: 17.9s\tremaining: 9m 54s\n",
      "29:\tlearn: 0.1628956\ttotal: 18.4s\tremaining: 9m 50s\n",
      "30:\tlearn: 0.1626037\ttotal: 18.9s\tremaining: 9m 46s\n",
      "31:\tlearn: 0.1623395\ttotal: 19.5s\tremaining: 9m 43s\n",
      "32:\tlearn: 0.1618706\ttotal: 20s\tremaining: 9m 41s\n",
      "33:\tlearn: 0.1615651\ttotal: 20.5s\tremaining: 9m 37s\n",
      "34:\tlearn: 0.1613200\ttotal: 21.1s\tremaining: 9m 35s\n",
      "35:\tlearn: 0.1609284\ttotal: 21.6s\tremaining: 9m 32s\n",
      "36:\tlearn: 0.1607575\ttotal: 22.2s\tremaining: 9m 33s\n",
      "37:\tlearn: 0.1604962\ttotal: 22.8s\tremaining: 9m 30s\n",
      "38:\tlearn: 0.1600925\ttotal: 23.3s\tremaining: 9m 29s\n",
      "39:\tlearn: 0.1598616\ttotal: 23.8s\tremaining: 9m 26s\n",
      "40:\tlearn: 0.1596605\ttotal: 24.4s\tremaining: 9m 24s\n",
      "41:\tlearn: 0.1594729\ttotal: 24.9s\tremaining: 9m 23s\n",
      "42:\tlearn: 0.1592925\ttotal: 25.7s\tremaining: 9m 26s\n",
      "43:\tlearn: 0.1590134\ttotal: 26.2s\tremaining: 9m 24s\n",
      "44:\tlearn: 0.1587936\ttotal: 26.7s\tremaining: 9m 21s\n",
      "45:\tlearn: 0.1587007\ttotal: 27.3s\tremaining: 9m 21s\n",
      "46:\tlearn: 0.1585945\ttotal: 27.8s\tremaining: 9m 19s\n",
      "47:\tlearn: 0.1585002\ttotal: 28.4s\tremaining: 9m 18s\n",
      "48:\tlearn: 0.1583879\ttotal: 29s\tremaining: 9m 18s\n",
      "49:\tlearn: 0.1581263\ttotal: 29.6s\tremaining: 9m 16s\n",
      "50:\tlearn: 0.1579244\ttotal: 30.2s\tremaining: 9m 15s\n",
      "51:\tlearn: 0.1578216\ttotal: 30.7s\tremaining: 9m 14s\n",
      "52:\tlearn: 0.1576504\ttotal: 31.3s\tremaining: 9m 13s\n",
      "53:\tlearn: 0.1575172\ttotal: 31.8s\tremaining: 9m 12s\n",
      "54:\tlearn: 0.1573125\ttotal: 32.4s\tremaining: 9m 11s\n",
      "55:\tlearn: 0.1571758\ttotal: 33s\tremaining: 9m 10s\n",
      "56:\tlearn: 0.1570606\ttotal: 33.6s\tremaining: 9m 10s\n",
      "57:\tlearn: 0.1569666\ttotal: 34.2s\tremaining: 9m 10s\n",
      "58:\tlearn: 0.1568898\ttotal: 34.9s\tremaining: 9m 11s\n",
      "59:\tlearn: 0.1567814\ttotal: 35.5s\tremaining: 9m 10s\n",
      "60:\tlearn: 0.1566215\ttotal: 36s\tremaining: 9m 9s\n",
      "61:\tlearn: 0.1565003\ttotal: 36.6s\tremaining: 9m 8s\n",
      "62:\tlearn: 0.1562907\ttotal: 37.2s\tremaining: 9m 7s\n",
      "63:\tlearn: 0.1561742\ttotal: 37.7s\tremaining: 9m 6s\n",
      "64:\tlearn: 0.1560425\ttotal: 38.3s\tremaining: 9m 5s\n",
      "65:\tlearn: 0.1559524\ttotal: 38.9s\tremaining: 9m 4s\n",
      "66:\tlearn: 0.1558730\ttotal: 39.5s\tremaining: 9m 4s\n",
      "67:\tlearn: 0.1558186\ttotal: 40.1s\tremaining: 9m 4s\n",
      "68:\tlearn: 0.1556785\ttotal: 40.7s\tremaining: 9m 3s\n",
      "69:\tlearn: 0.1555735\ttotal: 41.2s\tremaining: 9m 2s\n",
      "70:\tlearn: 0.1555106\ttotal: 41.8s\tremaining: 9m 1s\n",
      "71:\tlearn: 0.1554136\ttotal: 42.3s\tremaining: 9m\n",
      "72:\tlearn: 0.1552873\ttotal: 42.9s\tremaining: 8m 59s\n",
      "73:\tlearn: 0.1551797\ttotal: 43.5s\tremaining: 8m 59s\n",
      "74:\tlearn: 0.1551119\ttotal: 44.1s\tremaining: 8m 59s\n",
      "75:\tlearn: 0.1549957\ttotal: 44.8s\tremaining: 8m 59s\n",
      "76:\tlearn: 0.1548644\ttotal: 45.4s\tremaining: 8m 58s\n",
      "77:\tlearn: 0.1547944\ttotal: 46s\tremaining: 8m 58s\n",
      "78:\tlearn: 0.1546972\ttotal: 46.5s\tremaining: 8m 57s\n",
      "79:\tlearn: 0.1546058\ttotal: 47.1s\tremaining: 8m 56s\n",
      "80:\tlearn: 0.1545108\ttotal: 47.7s\tremaining: 8m 55s\n",
      "81:\tlearn: 0.1544146\ttotal: 48.2s\tremaining: 8m 54s\n",
      "82:\tlearn: 0.1542667\ttotal: 48.8s\tremaining: 8m 53s\n",
      "83:\tlearn: 0.1541920\ttotal: 49.5s\tremaining: 8m 53s\n",
      "84:\tlearn: 0.1541538\ttotal: 50s\tremaining: 8m 52s\n",
      "85:\tlearn: 0.1540697\ttotal: 50.7s\tremaining: 8m 53s\n",
      "86:\tlearn: 0.1540374\ttotal: 51.2s\tremaining: 8m 51s\n",
      "87:\tlearn: 0.1539439\ttotal: 51.8s\tremaining: 8m 51s\n",
      "88:\tlearn: 0.1538431\ttotal: 52.3s\tremaining: 8m 50s\n",
      "89:\tlearn: 0.1537193\ttotal: 52.9s\tremaining: 8m 49s\n",
      "90:\tlearn: 0.1536625\ttotal: 54.1s\tremaining: 8m 55s\n",
      "91:\tlearn: 0.1536036\ttotal: 55.3s\tremaining: 9m\n",
      "92:\tlearn: 0.1535441\ttotal: 56.4s\tremaining: 9m 4s\n",
      "93:\tlearn: 0.1534712\ttotal: 57s\tremaining: 9m 4s\n",
      "94:\tlearn: 0.1533948\ttotal: 57.8s\tremaining: 9m 4s\n",
      "95:\tlearn: 0.1532870\ttotal: 58.3s\tremaining: 9m 3s\n",
      "96:\tlearn: 0.1532366\ttotal: 59s\tremaining: 9m 4s\n",
      "97:\tlearn: 0.1531440\ttotal: 59.8s\tremaining: 9m 4s\n",
      "98:\tlearn: 0.1530714\ttotal: 1m\tremaining: 9m 3s\n",
      "99:\tlearn: 0.1529519\ttotal: 1m 1s\tremaining: 9m 3s\n",
      "100:\tlearn: 0.1528626\ttotal: 1m 1s\tremaining: 9m 2s\n",
      "101:\tlearn: 0.1527930\ttotal: 1m 2s\tremaining: 9m 2s\n",
      "102:\tlearn: 0.1526845\ttotal: 1m 2s\tremaining: 9m 2s\n",
      "103:\tlearn: 0.1525614\ttotal: 1m 3s\tremaining: 9m 2s\n",
      "104:\tlearn: 0.1524471\ttotal: 1m 4s\tremaining: 9m 1s\n",
      "105:\tlearn: 0.1524098\ttotal: 1m 4s\tremaining: 9m 1s\n",
      "106:\tlearn: 0.1523605\ttotal: 1m 5s\tremaining: 9m 1s\n",
      "107:\tlearn: 0.1522846\ttotal: 1m 6s\tremaining: 9m\n",
      "108:\tlearn: 0.1522255\ttotal: 1m 6s\tremaining: 8m 59s\n",
      "109:\tlearn: 0.1521440\ttotal: 1m 7s\tremaining: 8m 58s\n",
      "110:\tlearn: 0.1520951\ttotal: 1m 7s\tremaining: 8m 57s\n",
      "111:\tlearn: 0.1520944\ttotal: 1m 8s\tremaining: 8m 56s\n",
      "112:\tlearn: 0.1520269\ttotal: 1m 8s\tremaining: 8m 55s\n",
      "113:\tlearn: 0.1520263\ttotal: 1m 9s\tremaining: 8m 54s\n",
      "114:\tlearn: 0.1519615\ttotal: 1m 10s\tremaining: 8m 53s\n",
      "115:\tlearn: 0.1518886\ttotal: 1m 10s\tremaining: 8m 52s\n",
      "116:\tlearn: 0.1518068\ttotal: 1m 11s\tremaining: 8m 51s\n",
      "117:\tlearn: 0.1517470\ttotal: 1m 11s\tremaining: 8m 50s\n",
      "118:\tlearn: 0.1516733\ttotal: 1m 12s\tremaining: 8m 49s\n",
      "119:\tlearn: 0.1516124\ttotal: 1m 12s\tremaining: 8m 48s\n",
      "120:\tlearn: 0.1515636\ttotal: 1m 13s\tremaining: 8m 47s\n",
      "121:\tlearn: 0.1515260\ttotal: 1m 13s\tremaining: 8m 46s\n",
      "122:\tlearn: 0.1515260\ttotal: 1m 14s\tremaining: 8m 44s\n",
      "123:\tlearn: 0.1514670\ttotal: 1m 14s\tremaining: 8m 43s\n",
      "124:\tlearn: 0.1514062\ttotal: 1m 15s\tremaining: 8m 41s\n",
      "125:\tlearn: 0.1513750\ttotal: 1m 15s\tremaining: 8m 41s\n",
      "126:\tlearn: 0.1513162\ttotal: 1m 16s\tremaining: 8m 41s\n",
      "127:\tlearn: 0.1512749\ttotal: 1m 17s\tremaining: 8m 41s\n",
      "128:\tlearn: 0.1512336\ttotal: 1m 17s\tremaining: 8m 41s\n",
      "129:\tlearn: 0.1512336\ttotal: 1m 18s\tremaining: 8m 39s\n",
      "130:\tlearn: 0.1511639\ttotal: 1m 19s\tremaining: 8m 39s\n",
      "131:\tlearn: 0.1510808\ttotal: 1m 19s\tremaining: 8m 38s\n",
      "132:\tlearn: 0.1510123\ttotal: 1m 20s\tremaining: 8m 37s\n",
      "133:\tlearn: 0.1509666\ttotal: 1m 20s\tremaining: 8m 36s\n",
      "134:\tlearn: 0.1509666\ttotal: 1m 21s\tremaining: 8m 34s\n",
      "135:\tlearn: 0.1509244\ttotal: 1m 21s\tremaining: 8m 33s\n",
      "136:\tlearn: 0.1508439\ttotal: 1m 22s\tremaining: 8m 32s\n",
      "137:\tlearn: 0.1507945\ttotal: 1m 22s\tremaining: 8m 32s\n",
      "138:\tlearn: 0.1507485\ttotal: 1m 23s\tremaining: 8m 31s\n",
      "139:\tlearn: 0.1507081\ttotal: 1m 24s\tremaining: 8m 30s\n",
      "140:\tlearn: 0.1506586\ttotal: 1m 24s\tremaining: 8m 29s\n",
      "141:\tlearn: 0.1506120\ttotal: 1m 25s\tremaining: 8m 28s\n",
      "142:\tlearn: 0.1505484\ttotal: 1m 25s\tremaining: 8m 27s\n",
      "143:\tlearn: 0.1505091\ttotal: 1m 26s\tremaining: 8m 26s\n",
      "144:\tlearn: 0.1504698\ttotal: 1m 26s\tremaining: 8m 26s\n",
      "145:\tlearn: 0.1504415\ttotal: 1m 27s\tremaining: 8m 25s\n",
      "146:\tlearn: 0.1504158\ttotal: 1m 27s\tremaining: 8m 25s\n",
      "147:\tlearn: 0.1503777\ttotal: 1m 28s\tremaining: 8m 24s\n",
      "148:\tlearn: 0.1503036\ttotal: 1m 29s\tremaining: 8m 23s\n",
      "149:\tlearn: 0.1502693\ttotal: 1m 29s\tremaining: 8m 22s\n",
      "150:\tlearn: 0.1502488\ttotal: 1m 30s\tremaining: 8m 21s\n",
      "151:\tlearn: 0.1502301\ttotal: 1m 30s\tremaining: 8m 20s\n",
      "152:\tlearn: 0.1501669\ttotal: 1m 31s\tremaining: 8m 19s\n",
      "153:\tlearn: 0.1501529\ttotal: 1m 31s\tremaining: 8m 18s\n",
      "154:\tlearn: 0.1501244\ttotal: 1m 32s\tremaining: 8m 18s\n",
      "155:\tlearn: 0.1500432\ttotal: 1m 33s\tremaining: 8m 18s\n",
      "156:\tlearn: 0.1500428\ttotal: 1m 33s\tremaining: 8m 17s\n",
      "157:\tlearn: 0.1500285\ttotal: 1m 34s\tremaining: 8m 16s\n",
      "158:\tlearn: 0.1499886\ttotal: 1m 34s\tremaining: 8m 16s\n",
      "159:\tlearn: 0.1499553\ttotal: 1m 35s\tremaining: 8m 15s\n",
      "160:\tlearn: 0.1499176\ttotal: 1m 36s\tremaining: 8m 14s\n",
      "161:\tlearn: 0.1498854\ttotal: 1m 36s\tremaining: 8m 13s\n",
      "162:\tlearn: 0.1498324\ttotal: 1m 36s\tremaining: 8m 12s\n",
      "163:\tlearn: 0.1497785\ttotal: 1m 37s\tremaining: 8m 12s\n",
      "164:\tlearn: 0.1497432\ttotal: 1m 38s\tremaining: 8m 11s\n",
      "165:\tlearn: 0.1497014\ttotal: 1m 38s\tremaining: 8m 10s\n",
      "166:\tlearn: 0.1496653\ttotal: 1m 39s\tremaining: 8m 10s\n",
      "167:\tlearn: 0.1496120\ttotal: 1m 39s\tremaining: 8m 9s\n",
      "168:\tlearn: 0.1495659\ttotal: 1m 40s\tremaining: 8m 8s\n",
      "169:\tlearn: 0.1495161\ttotal: 1m 41s\tremaining: 8m 7s\n",
      "170:\tlearn: 0.1494746\ttotal: 1m 41s\tremaining: 8m 7s\n",
      "171:\tlearn: 0.1494024\ttotal: 1m 42s\tremaining: 8m 6s\n",
      "172:\tlearn: 0.1493400\ttotal: 1m 42s\tremaining: 8m 5s\n",
      "173:\tlearn: 0.1493155\ttotal: 1m 43s\tremaining: 8m 4s\n",
      "174:\tlearn: 0.1492748\ttotal: 1m 43s\tremaining: 8m 3s\n",
      "175:\tlearn: 0.1492333\ttotal: 1m 44s\tremaining: 8m 2s\n",
      "176:\tlearn: 0.1491836\ttotal: 1m 44s\tremaining: 8m 2s\n",
      "177:\tlearn: 0.1491336\ttotal: 1m 45s\tremaining: 8m 1s\n",
      "178:\tlearn: 0.1491095\ttotal: 1m 45s\tremaining: 8m\n",
      "179:\tlearn: 0.1490804\ttotal: 1m 46s\tremaining: 7m 59s\n",
      "180:\tlearn: 0.1490786\ttotal: 1m 46s\tremaining: 7m 58s\n",
      "181:\tlearn: 0.1490491\ttotal: 1m 47s\tremaining: 7m 58s\n",
      "182:\tlearn: 0.1489857\ttotal: 1m 48s\tremaining: 7m 58s\n",
      "183:\tlearn: 0.1489831\ttotal: 1m 49s\tremaining: 7m 58s\n",
      "184:\tlearn: 0.1489643\ttotal: 1m 49s\tremaining: 7m 57s\n",
      "185:\tlearn: 0.1489391\ttotal: 1m 50s\tremaining: 7m 57s\n",
      "186:\tlearn: 0.1489170\ttotal: 1m 50s\tremaining: 7m 57s\n",
      "187:\tlearn: 0.1488902\ttotal: 1m 51s\tremaining: 7m 56s\n",
      "188:\tlearn: 0.1488671\ttotal: 1m 52s\tremaining: 7m 56s\n",
      "189:\tlearn: 0.1488304\ttotal: 1m 52s\tremaining: 7m 55s\n",
      "190:\tlearn: 0.1487795\ttotal: 1m 53s\tremaining: 7m 54s\n",
      "191:\tlearn: 0.1487314\ttotal: 1m 53s\tremaining: 7m 54s\n",
      "192:\tlearn: 0.1487056\ttotal: 1m 54s\tremaining: 7m 53s\n",
      "193:\tlearn: 0.1486790\ttotal: 1m 55s\tremaining: 7m 52s\n",
      "194:\tlearn: 0.1486527\ttotal: 1m 55s\tremaining: 7m 52s\n",
      "195:\tlearn: 0.1486200\ttotal: 1m 56s\tremaining: 7m 51s\n",
      "196:\tlearn: 0.1485807\ttotal: 1m 56s\tremaining: 7m 51s\n",
      "197:\tlearn: 0.1485485\ttotal: 1m 57s\tremaining: 7m 50s\n",
      "198:\tlearn: 0.1484854\ttotal: 1m 58s\tremaining: 7m 50s\n",
      "199:\tlearn: 0.1484607\ttotal: 1m 59s\tremaining: 7m 50s\n",
      "200:\tlearn: 0.1484592\ttotal: 1m 59s\tremaining: 7m 49s\n",
      "201:\tlearn: 0.1484178\ttotal: 2m\tremaining: 7m 49s\n",
      "202:\tlearn: 0.1484177\ttotal: 2m\tremaining: 7m 48s\n",
      "203:\tlearn: 0.1483793\ttotal: 2m 1s\tremaining: 7m 48s\n",
      "204:\tlearn: 0.1483439\ttotal: 2m 1s\tremaining: 7m 47s\n",
      "205:\tlearn: 0.1483186\ttotal: 2m 2s\tremaining: 7m 46s\n",
      "206:\tlearn: 0.1483186\ttotal: 2m 2s\tremaining: 7m 45s\n",
      "207:\tlearn: 0.1482723\ttotal: 2m 3s\tremaining: 7m 45s\n",
      "208:\tlearn: 0.1482067\ttotal: 2m 4s\tremaining: 7m 44s\n",
      "209:\tlearn: 0.1481834\ttotal: 2m 4s\tremaining: 7m 44s\n",
      "210:\tlearn: 0.1481821\ttotal: 2m 5s\tremaining: 7m 43s\n",
      "211:\tlearn: 0.1481594\ttotal: 2m 5s\tremaining: 7m 42s\n",
      "212:\tlearn: 0.1481329\ttotal: 2m 6s\tremaining: 7m 41s\n",
      "213:\tlearn: 0.1481096\ttotal: 2m 6s\tremaining: 7m 40s\n",
      "214:\tlearn: 0.1480884\ttotal: 2m 7s\tremaining: 7m 40s\n",
      "215:\tlearn: 0.1480603\ttotal: 2m 8s\tremaining: 7m 39s\n",
      "216:\tlearn: 0.1480551\ttotal: 2m 8s\tremaining: 7m 38s\n",
      "217:\tlearn: 0.1480283\ttotal: 2m 9s\tremaining: 7m 38s\n",
      "218:\tlearn: 0.1480171\ttotal: 2m 9s\tremaining: 7m 37s\n",
      "219:\tlearn: 0.1479756\ttotal: 2m 10s\tremaining: 7m 36s\n",
      "220:\tlearn: 0.1479587\ttotal: 2m 10s\tremaining: 7m 36s\n",
      "221:\tlearn: 0.1479236\ttotal: 2m 11s\tremaining: 7m 35s\n",
      "222:\tlearn: 0.1478832\ttotal: 2m 12s\tremaining: 7m 34s\n",
      "223:\tlearn: 0.1478805\ttotal: 2m 12s\tremaining: 7m 34s\n",
      "224:\tlearn: 0.1478797\ttotal: 2m 13s\tremaining: 7m 33s\n",
      "225:\tlearn: 0.1478740\ttotal: 2m 13s\tremaining: 7m 32s\n",
      "226:\tlearn: 0.1478141\ttotal: 2m 14s\tremaining: 7m 31s\n",
      "227:\tlearn: 0.1477859\ttotal: 2m 14s\tremaining: 7m 31s\n",
      "228:\tlearn: 0.1477412\ttotal: 2m 15s\tremaining: 7m 30s\n",
      "229:\tlearn: 0.1476839\ttotal: 2m 15s\tremaining: 7m 29s\n",
      "230:\tlearn: 0.1476516\ttotal: 2m 16s\tremaining: 7m 29s\n",
      "231:\tlearn: 0.1476371\ttotal: 2m 17s\tremaining: 7m 28s\n",
      "232:\tlearn: 0.1475967\ttotal: 2m 17s\tremaining: 7m 28s\n",
      "233:\tlearn: 0.1475567\ttotal: 2m 18s\tremaining: 7m 27s\n",
      "234:\tlearn: 0.1475345\ttotal: 2m 18s\tremaining: 7m 26s\n",
      "235:\tlearn: 0.1474867\ttotal: 2m 19s\tremaining: 7m 25s\n",
      "236:\tlearn: 0.1474578\ttotal: 2m 20s\tremaining: 7m 25s\n",
      "237:\tlearn: 0.1474195\ttotal: 2m 20s\tremaining: 7m 24s\n",
      "238:\tlearn: 0.1474107\ttotal: 2m 21s\tremaining: 7m 24s\n",
      "239:\tlearn: 0.1473705\ttotal: 2m 21s\tremaining: 7m 23s\n",
      "240:\tlearn: 0.1473401\ttotal: 2m 22s\tremaining: 7m 23s\n",
      "241:\tlearn: 0.1473104\ttotal: 2m 22s\tremaining: 7m 22s\n",
      "242:\tlearn: 0.1473096\ttotal: 2m 23s\tremaining: 7m 21s\n",
      "243:\tlearn: 0.1472890\ttotal: 2m 24s\tremaining: 7m 21s\n",
      "244:\tlearn: 0.1472618\ttotal: 2m 24s\tremaining: 7m 20s\n",
      "245:\tlearn: 0.1472328\ttotal: 2m 25s\tremaining: 7m 20s\n",
      "246:\tlearn: 0.1472216\ttotal: 2m 25s\tremaining: 7m 19s\n",
      "247:\tlearn: 0.1471887\ttotal: 2m 26s\tremaining: 7m 18s\n",
      "248:\tlearn: 0.1471446\ttotal: 2m 27s\tremaining: 7m 18s\n",
      "249:\tlearn: 0.1471299\ttotal: 2m 27s\tremaining: 7m 17s\n",
      "250:\tlearn: 0.1470710\ttotal: 2m 28s\tremaining: 7m 16s\n",
      "251:\tlearn: 0.1470696\ttotal: 2m 28s\tremaining: 7m 16s\n",
      "252:\tlearn: 0.1470486\ttotal: 2m 29s\tremaining: 7m 15s\n",
      "253:\tlearn: 0.1470158\ttotal: 2m 29s\tremaining: 7m 14s\n",
      "254:\tlearn: 0.1469745\ttotal: 2m 30s\tremaining: 7m 13s\n",
      "255:\tlearn: 0.1469474\ttotal: 2m 30s\tremaining: 7m 13s\n",
      "256:\tlearn: 0.1469148\ttotal: 2m 31s\tremaining: 7m 13s\n",
      "257:\tlearn: 0.1468803\ttotal: 2m 32s\tremaining: 7m 12s\n",
      "258:\tlearn: 0.1468780\ttotal: 2m 32s\tremaining: 7m 11s\n",
      "259:\tlearn: 0.1468763\ttotal: 2m 33s\tremaining: 7m 10s\n",
      "260:\tlearn: 0.1468541\ttotal: 2m 33s\tremaining: 7m 10s\n",
      "261:\tlearn: 0.1468349\ttotal: 2m 34s\tremaining: 7m 9s\n",
      "262:\tlearn: 0.1468131\ttotal: 2m 35s\tremaining: 7m 9s\n",
      "263:\tlearn: 0.1467784\ttotal: 2m 35s\tremaining: 7m 8s\n",
      "264:\tlearn: 0.1467548\ttotal: 2m 36s\tremaining: 7m 7s\n",
      "265:\tlearn: 0.1467252\ttotal: 2m 36s\tremaining: 7m 7s\n",
      "266:\tlearn: 0.1467045\ttotal: 2m 37s\tremaining: 7m 6s\n",
      "267:\tlearn: 0.1466883\ttotal: 2m 37s\tremaining: 7m 5s\n",
      "268:\tlearn: 0.1466616\ttotal: 2m 38s\tremaining: 7m 5s\n",
      "269:\tlearn: 0.1466310\ttotal: 2m 39s\tremaining: 7m 4s\n",
      "270:\tlearn: 0.1466017\ttotal: 2m 39s\tremaining: 7m 4s\n",
      "271:\tlearn: 0.1465878\ttotal: 2m 40s\tremaining: 7m 3s\n",
      "272:\tlearn: 0.1465529\ttotal: 2m 40s\tremaining: 7m 3s\n",
      "273:\tlearn: 0.1465123\ttotal: 2m 41s\tremaining: 7m 3s\n",
      "274:\tlearn: 0.1465004\ttotal: 2m 43s\tremaining: 7m 6s\n",
      "275:\tlearn: 0.1464719\ttotal: 2m 44s\tremaining: 7m 6s\n",
      "276:\tlearn: 0.1464559\ttotal: 2m 45s\tremaining: 7m 6s\n",
      "277:\tlearn: 0.1464559\ttotal: 2m 45s\tremaining: 7m 5s\n",
      "278:\tlearn: 0.1464559\ttotal: 2m 46s\tremaining: 7m 4s\n",
      "279:\tlearn: 0.1464559\ttotal: 2m 46s\tremaining: 7m 3s\n",
      "280:\tlearn: 0.1464407\ttotal: 2m 47s\tremaining: 7m 2s\n",
      "281:\tlearn: 0.1464262\ttotal: 2m 48s\tremaining: 7m 2s\n",
      "282:\tlearn: 0.1464015\ttotal: 2m 48s\tremaining: 7m 1s\n",
      "283:\tlearn: 0.1463760\ttotal: 2m 49s\tremaining: 7m 1s\n",
      "284:\tlearn: 0.1463528\ttotal: 2m 50s\tremaining: 7m 1s\n",
      "285:\tlearn: 0.1462893\ttotal: 2m 50s\tremaining: 7m\n",
      "286:\tlearn: 0.1462444\ttotal: 2m 51s\tremaining: 6m 59s\n",
      "287:\tlearn: 0.1462098\ttotal: 2m 51s\tremaining: 6m 59s\n",
      "288:\tlearn: 0.1461833\ttotal: 2m 52s\tremaining: 6m 58s\n",
      "289:\tlearn: 0.1461831\ttotal: 2m 52s\tremaining: 6m 58s\n",
      "290:\tlearn: 0.1461619\ttotal: 2m 53s\tremaining: 6m 57s\n",
      "291:\tlearn: 0.1461275\ttotal: 2m 54s\tremaining: 6m 56s\n",
      "292:\tlearn: 0.1460975\ttotal: 2m 54s\tremaining: 6m 56s\n",
      "293:\tlearn: 0.1460853\ttotal: 2m 55s\tremaining: 6m 55s\n",
      "294:\tlearn: 0.1460734\ttotal: 2m 55s\tremaining: 6m 54s\n",
      "295:\tlearn: 0.1460347\ttotal: 2m 56s\tremaining: 6m 54s\n",
      "296:\tlearn: 0.1460070\ttotal: 2m 57s\tremaining: 6m 53s\n",
      "297:\tlearn: 0.1459862\ttotal: 2m 57s\tremaining: 6m 53s\n",
      "298:\tlearn: 0.1459541\ttotal: 2m 58s\tremaining: 6m 53s\n",
      "299:\tlearn: 0.1459223\ttotal: 2m 59s\tremaining: 6m 53s\n",
      "300:\tlearn: 0.1458447\ttotal: 2m 59s\tremaining: 6m 52s\n",
      "301:\tlearn: 0.1458121\ttotal: 3m\tremaining: 6m 51s\n",
      "302:\tlearn: 0.1457628\ttotal: 3m 1s\tremaining: 6m 51s\n",
      "303:\tlearn: 0.1457627\ttotal: 3m 1s\tremaining: 6m 50s\n",
      "304:\tlearn: 0.1457252\ttotal: 3m 2s\tremaining: 6m 50s\n",
      "305:\tlearn: 0.1456920\ttotal: 3m 3s\tremaining: 6m 49s\n",
      "306:\tlearn: 0.1456633\ttotal: 3m 3s\tremaining: 6m 49s\n",
      "307:\tlearn: 0.1456624\ttotal: 3m 4s\tremaining: 6m 48s\n",
      "308:\tlearn: 0.1456179\ttotal: 3m 5s\tremaining: 6m 48s\n",
      "309:\tlearn: 0.1455980\ttotal: 3m 5s\tremaining: 6m 47s\n",
      "310:\tlearn: 0.1455817\ttotal: 3m 6s\tremaining: 6m 47s\n",
      "311:\tlearn: 0.1455503\ttotal: 3m 6s\tremaining: 6m 46s\n",
      "312:\tlearn: 0.1455079\ttotal: 3m 7s\tremaining: 6m 46s\n",
      "313:\tlearn: 0.1454903\ttotal: 3m 8s\tremaining: 6m 45s\n",
      "314:\tlearn: 0.1454733\ttotal: 3m 8s\tremaining: 6m 45s\n",
      "315:\tlearn: 0.1454330\ttotal: 3m 9s\tremaining: 6m 44s\n",
      "316:\tlearn: 0.1453936\ttotal: 3m 10s\tremaining: 6m 44s\n",
      "317:\tlearn: 0.1453647\ttotal: 3m 10s\tremaining: 6m 43s\n",
      "318:\tlearn: 0.1453291\ttotal: 3m 11s\tremaining: 6m 43s\n",
      "319:\tlearn: 0.1453245\ttotal: 3m 12s\tremaining: 6m 42s\n",
      "320:\tlearn: 0.1452936\ttotal: 3m 12s\tremaining: 6m 42s\n",
      "321:\tlearn: 0.1452551\ttotal: 3m 13s\tremaining: 6m 41s\n",
      "322:\tlearn: 0.1452284\ttotal: 3m 14s\tremaining: 6m 41s\n",
      "323:\tlearn: 0.1452000\ttotal: 3m 14s\tremaining: 6m 41s\n",
      "324:\tlearn: 0.1451852\ttotal: 3m 15s\tremaining: 6m 40s\n",
      "325:\tlearn: 0.1451524\ttotal: 3m 16s\tremaining: 6m 40s\n",
      "326:\tlearn: 0.1451238\ttotal: 3m 16s\tremaining: 6m 39s\n",
      "327:\tlearn: 0.1450941\ttotal: 3m 17s\tremaining: 6m 39s\n",
      "328:\tlearn: 0.1450539\ttotal: 3m 18s\tremaining: 6m 38s\n",
      "329:\tlearn: 0.1450040\ttotal: 3m 18s\tremaining: 6m 38s\n",
      "330:\tlearn: 0.1449965\ttotal: 3m 19s\tremaining: 6m 37s\n",
      "331:\tlearn: 0.1449688\ttotal: 3m 20s\tremaining: 6m 37s\n",
      "332:\tlearn: 0.1449668\ttotal: 3m 20s\tremaining: 6m 36s\n",
      "333:\tlearn: 0.1449370\ttotal: 3m 21s\tremaining: 6m 36s\n",
      "334:\tlearn: 0.1449088\ttotal: 3m 21s\tremaining: 6m 35s\n",
      "335:\tlearn: 0.1448772\ttotal: 3m 22s\tremaining: 6m 34s\n",
      "336:\tlearn: 0.1448756\ttotal: 3m 23s\tremaining: 6m 34s\n",
      "337:\tlearn: 0.1448741\ttotal: 3m 23s\tremaining: 6m 33s\n",
      "338:\tlearn: 0.1448426\ttotal: 3m 24s\tremaining: 6m 32s\n",
      "339:\tlearn: 0.1448377\ttotal: 3m 24s\tremaining: 6m 32s\n",
      "340:\tlearn: 0.1448257\ttotal: 3m 25s\tremaining: 6m 31s\n",
      "341:\tlearn: 0.1447991\ttotal: 3m 26s\tremaining: 6m 31s\n",
      "342:\tlearn: 0.1447923\ttotal: 3m 26s\tremaining: 6m 30s\n",
      "343:\tlearn: 0.1447765\ttotal: 3m 27s\tremaining: 6m 29s\n",
      "344:\tlearn: 0.1447650\ttotal: 3m 27s\tremaining: 6m 29s\n",
      "345:\tlearn: 0.1447483\ttotal: 3m 28s\tremaining: 6m 28s\n",
      "346:\tlearn: 0.1447273\ttotal: 3m 28s\tremaining: 6m 27s\n",
      "347:\tlearn: 0.1447103\ttotal: 3m 29s\tremaining: 6m 27s\n",
      "348:\tlearn: 0.1447008\ttotal: 3m 30s\tremaining: 6m 26s\n",
      "349:\tlearn: 0.1446809\ttotal: 3m 30s\tremaining: 6m 26s\n",
      "350:\tlearn: 0.1446455\ttotal: 3m 31s\tremaining: 6m 25s\n",
      "351:\tlearn: 0.1446039\ttotal: 3m 32s\tremaining: 6m 25s\n",
      "352:\tlearn: 0.1445510\ttotal: 3m 32s\tremaining: 6m 24s\n",
      "353:\tlearn: 0.1445433\ttotal: 3m 33s\tremaining: 6m 24s\n",
      "354:\tlearn: 0.1445234\ttotal: 3m 34s\tremaining: 6m 23s\n",
      "355:\tlearn: 0.1445109\ttotal: 3m 34s\tremaining: 6m 22s\n",
      "356:\tlearn: 0.1444952\ttotal: 3m 35s\tremaining: 6m 22s\n",
      "357:\tlearn: 0.1444763\ttotal: 3m 35s\tremaining: 6m 21s\n",
      "358:\tlearn: 0.1444019\ttotal: 3m 36s\tremaining: 6m 21s\n",
      "359:\tlearn: 0.1444007\ttotal: 3m 37s\tremaining: 6m 20s\n",
      "360:\tlearn: 0.1443562\ttotal: 3m 37s\tremaining: 6m 19s\n",
      "361:\tlearn: 0.1443397\ttotal: 3m 38s\tremaining: 6m 19s\n",
      "362:\tlearn: 0.1443327\ttotal: 3m 38s\tremaining: 6m 18s\n",
      "363:\tlearn: 0.1443324\ttotal: 3m 39s\tremaining: 6m 17s\n",
      "364:\tlearn: 0.1443092\ttotal: 3m 40s\tremaining: 6m 17s\n",
      "365:\tlearn: 0.1442861\ttotal: 3m 40s\tremaining: 6m 16s\n",
      "366:\tlearn: 0.1442748\ttotal: 3m 41s\tremaining: 6m 15s\n",
      "367:\tlearn: 0.1442566\ttotal: 3m 41s\tremaining: 6m 15s\n",
      "368:\tlearn: 0.1442563\ttotal: 3m 42s\tremaining: 6m 14s\n",
      "369:\tlearn: 0.1442395\ttotal: 3m 42s\tremaining: 6m 14s\n",
      "370:\tlearn: 0.1442088\ttotal: 3m 43s\tremaining: 6m 13s\n",
      "371:\tlearn: 0.1441862\ttotal: 3m 44s\tremaining: 6m 12s\n",
      "372:\tlearn: 0.1441700\ttotal: 3m 44s\tremaining: 6m 12s\n",
      "373:\tlearn: 0.1441383\ttotal: 3m 45s\tremaining: 6m 11s\n",
      "374:\tlearn: 0.1441080\ttotal: 3m 45s\tremaining: 6m 11s\n",
      "375:\tlearn: 0.1440820\ttotal: 3m 46s\tremaining: 6m 10s\n",
      "376:\tlearn: 0.1440480\ttotal: 3m 47s\tremaining: 6m 9s\n",
      "377:\tlearn: 0.1440340\ttotal: 3m 47s\tremaining: 6m 9s\n",
      "378:\tlearn: 0.1440202\ttotal: 3m 48s\tremaining: 6m 8s\n",
      "379:\tlearn: 0.1440128\ttotal: 3m 48s\tremaining: 6m 8s\n",
      "380:\tlearn: 0.1440011\ttotal: 3m 49s\tremaining: 6m 7s\n",
      "381:\tlearn: 0.1439774\ttotal: 3m 50s\tremaining: 6m 7s\n",
      "382:\tlearn: 0.1439517\ttotal: 3m 51s\tremaining: 6m 7s\n",
      "383:\tlearn: 0.1439177\ttotal: 3m 52s\tremaining: 6m 6s\n",
      "384:\tlearn: 0.1438786\ttotal: 3m 52s\tremaining: 6m 6s\n",
      "385:\tlearn: 0.1438706\ttotal: 3m 53s\tremaining: 6m 5s\n",
      "386:\tlearn: 0.1438690\ttotal: 3m 53s\tremaining: 6m 5s\n",
      "387:\tlearn: 0.1438416\ttotal: 3m 54s\tremaining: 6m 4s\n",
      "388:\tlearn: 0.1438079\ttotal: 3m 55s\tremaining: 6m 4s\n",
      "389:\tlearn: 0.1437911\ttotal: 3m 56s\tremaining: 6m 4s\n",
      "390:\tlearn: 0.1437283\ttotal: 3m 57s\tremaining: 6m 4s\n",
      "391:\tlearn: 0.1436871\ttotal: 3m 58s\tremaining: 6m 4s\n",
      "392:\tlearn: 0.1436804\ttotal: 3m 59s\tremaining: 6m 4s\n",
      "393:\tlearn: 0.1436539\ttotal: 4m\tremaining: 6m 4s\n",
      "394:\tlearn: 0.1436223\ttotal: 4m 1s\tremaining: 6m 3s\n",
      "395:\tlearn: 0.1435823\ttotal: 4m 1s\tremaining: 6m 3s\n",
      "396:\tlearn: 0.1435643\ttotal: 4m 2s\tremaining: 6m 2s\n",
      "397:\tlearn: 0.1435489\ttotal: 4m 2s\tremaining: 6m 1s\n",
      "398:\tlearn: 0.1435304\ttotal: 4m 3s\tremaining: 6m 1s\n",
      "399:\tlearn: 0.1435243\ttotal: 4m 4s\tremaining: 6m\n",
      "400:\tlearn: 0.1435105\ttotal: 4m 4s\tremaining: 6m\n",
      "401:\tlearn: 0.1434799\ttotal: 4m 5s\tremaining: 5m 59s\n",
      "402:\tlearn: 0.1434572\ttotal: 4m 6s\tremaining: 5m 58s\n",
      "403:\tlearn: 0.1434351\ttotal: 4m 6s\tremaining: 5m 58s\n",
      "404:\tlearn: 0.1433817\ttotal: 4m 7s\tremaining: 5m 58s\n",
      "405:\tlearn: 0.1433553\ttotal: 4m 8s\tremaining: 5m 57s\n",
      "406:\tlearn: 0.1433446\ttotal: 4m 8s\tremaining: 5m 56s\n",
      "407:\tlearn: 0.1433209\ttotal: 4m 9s\tremaining: 5m 56s\n",
      "408:\tlearn: 0.1432869\ttotal: 4m 10s\tremaining: 5m 56s\n",
      "409:\tlearn: 0.1432594\ttotal: 4m 10s\tremaining: 5m 55s\n",
      "410:\tlearn: 0.1432416\ttotal: 4m 11s\tremaining: 5m 54s\n",
      "411:\tlearn: 0.1432312\ttotal: 4m 12s\tremaining: 5m 54s\n",
      "412:\tlearn: 0.1432206\ttotal: 4m 12s\tremaining: 5m 53s\n",
      "413:\tlearn: 0.1431936\ttotal: 4m 13s\tremaining: 5m 53s\n",
      "414:\tlearn: 0.1431713\ttotal: 4m 14s\tremaining: 5m 52s\n",
      "415:\tlearn: 0.1431510\ttotal: 4m 14s\tremaining: 5m 52s\n",
      "416:\tlearn: 0.1431255\ttotal: 4m 15s\tremaining: 5m 51s\n",
      "417:\tlearn: 0.1431122\ttotal: 4m 16s\tremaining: 5m 50s\n",
      "418:\tlearn: 0.1431093\ttotal: 4m 16s\tremaining: 5m 50s\n",
      "419:\tlearn: 0.1430880\ttotal: 4m 17s\tremaining: 5m 49s\n",
      "420:\tlearn: 0.1430843\ttotal: 4m 18s\tremaining: 5m 49s\n",
      "421:\tlearn: 0.1430734\ttotal: 4m 18s\tremaining: 5m 48s\n",
      "422:\tlearn: 0.1430392\ttotal: 4m 19s\tremaining: 5m 48s\n",
      "423:\tlearn: 0.1430036\ttotal: 4m 20s\tremaining: 5m 47s\n",
      "424:\tlearn: 0.1429848\ttotal: 4m 20s\tremaining: 5m 47s\n",
      "425:\tlearn: 0.1429548\ttotal: 4m 21s\tremaining: 5m 46s\n",
      "426:\tlearn: 0.1429345\ttotal: 4m 22s\tremaining: 5m 46s\n",
      "427:\tlearn: 0.1429072\ttotal: 4m 22s\tremaining: 5m 45s\n",
      "428:\tlearn: 0.1428832\ttotal: 4m 23s\tremaining: 5m 45s\n",
      "429:\tlearn: 0.1428596\ttotal: 4m 24s\tremaining: 5m 44s\n",
      "430:\tlearn: 0.1428590\ttotal: 4m 24s\tremaining: 5m 43s\n",
      "431:\tlearn: 0.1428454\ttotal: 4m 25s\tremaining: 5m 43s\n",
      "432:\tlearn: 0.1428037\ttotal: 4m 26s\tremaining: 5m 42s\n",
      "433:\tlearn: 0.1427930\ttotal: 4m 26s\tremaining: 5m 42s\n",
      "434:\tlearn: 0.1427700\ttotal: 4m 27s\tremaining: 5m 41s\n",
      "435:\tlearn: 0.1427339\ttotal: 4m 28s\tremaining: 5m 41s\n",
      "436:\tlearn: 0.1427042\ttotal: 4m 28s\tremaining: 5m 40s\n",
      "437:\tlearn: 0.1426760\ttotal: 4m 29s\tremaining: 5m 40s\n",
      "438:\tlearn: 0.1426521\ttotal: 4m 30s\tremaining: 5m 39s\n",
      "439:\tlearn: 0.1426245\ttotal: 4m 30s\tremaining: 5m 39s\n",
      "440:\tlearn: 0.1426028\ttotal: 4m 31s\tremaining: 5m 38s\n",
      "441:\tlearn: 0.1425671\ttotal: 4m 32s\tremaining: 5m 38s\n",
      "442:\tlearn: 0.1425596\ttotal: 4m 32s\tremaining: 5m 37s\n",
      "443:\tlearn: 0.1425589\ttotal: 4m 33s\tremaining: 5m 36s\n",
      "444:\tlearn: 0.1425306\ttotal: 4m 34s\tremaining: 5m 36s\n",
      "445:\tlearn: 0.1424990\ttotal: 4m 34s\tremaining: 5m 35s\n",
      "446:\tlearn: 0.1424525\ttotal: 4m 35s\tremaining: 5m 35s\n",
      "447:\tlearn: 0.1424137\ttotal: 4m 35s\tremaining: 5m 34s\n",
      "448:\tlearn: 0.1423814\ttotal: 4m 36s\tremaining: 5m 33s\n",
      "449:\tlearn: 0.1423775\ttotal: 4m 37s\tremaining: 5m 33s\n",
      "450:\tlearn: 0.1423494\ttotal: 4m 37s\tremaining: 5m 32s\n",
      "451:\tlearn: 0.1423289\ttotal: 4m 38s\tremaining: 5m 32s\n",
      "452:\tlearn: 0.1423041\ttotal: 4m 39s\tremaining: 5m 31s\n",
      "453:\tlearn: 0.1422930\ttotal: 4m 39s\tremaining: 5m 30s\n",
      "454:\tlearn: 0.1422673\ttotal: 4m 40s\tremaining: 5m 30s\n",
      "455:\tlearn: 0.1422466\ttotal: 4m 40s\tremaining: 5m 29s\n",
      "456:\tlearn: 0.1422087\ttotal: 4m 41s\tremaining: 5m 29s\n",
      "457:\tlearn: 0.1421997\ttotal: 4m 42s\tremaining: 5m 28s\n",
      "458:\tlearn: 0.1421836\ttotal: 4m 42s\tremaining: 5m 27s\n",
      "459:\tlearn: 0.1421782\ttotal: 4m 43s\tremaining: 5m 27s\n",
      "460:\tlearn: 0.1421600\ttotal: 4m 44s\tremaining: 5m 26s\n",
      "461:\tlearn: 0.1421396\ttotal: 4m 44s\tremaining: 5m 26s\n",
      "462:\tlearn: 0.1421241\ttotal: 4m 45s\tremaining: 5m 25s\n",
      "463:\tlearn: 0.1420974\ttotal: 4m 46s\tremaining: 5m 24s\n",
      "464:\tlearn: 0.1420610\ttotal: 4m 46s\tremaining: 5m 24s\n",
      "465:\tlearn: 0.1420472\ttotal: 4m 47s\tremaining: 5m 23s\n",
      "466:\tlearn: 0.1420096\ttotal: 4m 47s\tremaining: 5m 23s\n",
      "467:\tlearn: 0.1419725\ttotal: 4m 48s\tremaining: 5m 22s\n",
      "468:\tlearn: 0.1419580\ttotal: 4m 49s\tremaining: 5m 22s\n",
      "469:\tlearn: 0.1419371\ttotal: 4m 50s\tremaining: 5m 21s\n",
      "470:\tlearn: 0.1418681\ttotal: 4m 50s\tremaining: 5m 20s\n",
      "471:\tlearn: 0.1418443\ttotal: 4m 51s\tremaining: 5m 20s\n",
      "472:\tlearn: 0.1418185\ttotal: 4m 51s\tremaining: 5m 19s\n",
      "473:\tlearn: 0.1417880\ttotal: 4m 52s\tremaining: 5m 19s\n",
      "474:\tlearn: 0.1417438\ttotal: 4m 53s\tremaining: 5m 18s\n",
      "475:\tlearn: 0.1417181\ttotal: 4m 53s\tremaining: 5m 17s\n",
      "476:\tlearn: 0.1416734\ttotal: 4m 54s\tremaining: 5m 17s\n",
      "477:\tlearn: 0.1416600\ttotal: 4m 55s\tremaining: 5m 16s\n",
      "478:\tlearn: 0.1416596\ttotal: 4m 55s\tremaining: 5m 16s\n",
      "479:\tlearn: 0.1416492\ttotal: 4m 56s\tremaining: 5m 15s\n",
      "480:\tlearn: 0.1416456\ttotal: 4m 57s\tremaining: 5m 15s\n",
      "481:\tlearn: 0.1416219\ttotal: 4m 58s\tremaining: 5m 14s\n",
      "482:\tlearn: 0.1416203\ttotal: 4m 58s\tremaining: 5m 14s\n",
      "483:\tlearn: 0.1416051\ttotal: 4m 59s\tremaining: 5m 13s\n",
      "484:\tlearn: 0.1415877\ttotal: 5m\tremaining: 5m 13s\n",
      "485:\tlearn: 0.1415586\ttotal: 5m\tremaining: 5m 12s\n",
      "486:\tlearn: 0.1415299\ttotal: 5m 1s\tremaining: 5m 12s\n",
      "487:\tlearn: 0.1415096\ttotal: 5m 2s\tremaining: 5m 11s\n",
      "488:\tlearn: 0.1414884\ttotal: 5m 2s\tremaining: 5m 10s\n",
      "489:\tlearn: 0.1414773\ttotal: 5m 3s\tremaining: 5m 10s\n",
      "490:\tlearn: 0.1414625\ttotal: 5m 4s\tremaining: 5m 9s\n",
      "491:\tlearn: 0.1414472\ttotal: 5m 4s\tremaining: 5m 9s\n",
      "492:\tlearn: 0.1414299\ttotal: 5m 5s\tremaining: 5m 8s\n",
      "493:\tlearn: 0.1413870\ttotal: 5m 6s\tremaining: 5m 8s\n",
      "494:\tlearn: 0.1413586\ttotal: 5m 7s\tremaining: 5m 7s\n",
      "495:\tlearn: 0.1413329\ttotal: 5m 7s\tremaining: 5m 7s\n",
      "496:\tlearn: 0.1413222\ttotal: 5m 8s\tremaining: 5m 6s\n",
      "497:\tlearn: 0.1413053\ttotal: 5m 9s\tremaining: 5m 5s\n",
      "498:\tlearn: 0.1412901\ttotal: 5m 9s\tremaining: 5m 5s\n",
      "499:\tlearn: 0.1412638\ttotal: 5m 10s\tremaining: 5m 4s\n",
      "500:\tlearn: 0.1412381\ttotal: 5m 11s\tremaining: 5m 4s\n",
      "501:\tlearn: 0.1412283\ttotal: 5m 11s\tremaining: 5m 3s\n",
      "502:\tlearn: 0.1412268\ttotal: 5m 12s\tremaining: 5m 2s\n",
      "503:\tlearn: 0.1412041\ttotal: 5m 12s\tremaining: 5m 2s\n",
      "504:\tlearn: 0.1411760\ttotal: 5m 13s\tremaining: 5m 1s\n",
      "505:\tlearn: 0.1411591\ttotal: 5m 14s\tremaining: 5m 1s\n",
      "506:\tlearn: 0.1411415\ttotal: 5m 14s\tremaining: 5m\n",
      "507:\tlearn: 0.1411369\ttotal: 5m 15s\tremaining: 4m 59s\n",
      "508:\tlearn: 0.1411362\ttotal: 5m 15s\tremaining: 4m 59s\n",
      "509:\tlearn: 0.1411140\ttotal: 5m 16s\tremaining: 4m 58s\n",
      "510:\tlearn: 0.1410971\ttotal: 5m 17s\tremaining: 4m 57s\n",
      "511:\tlearn: 0.1410716\ttotal: 5m 17s\tremaining: 4m 57s\n",
      "512:\tlearn: 0.1410645\ttotal: 5m 18s\tremaining: 4m 56s\n",
      "513:\tlearn: 0.1410496\ttotal: 5m 19s\tremaining: 4m 56s\n",
      "514:\tlearn: 0.1410251\ttotal: 5m 19s\tremaining: 4m 55s\n",
      "515:\tlearn: 0.1409866\ttotal: 5m 20s\tremaining: 4m 55s\n",
      "516:\tlearn: 0.1409862\ttotal: 5m 21s\tremaining: 4m 54s\n",
      "517:\tlearn: 0.1409748\ttotal: 5m 21s\tremaining: 4m 53s\n",
      "518:\tlearn: 0.1409623\ttotal: 5m 22s\tremaining: 4m 53s\n",
      "519:\tlearn: 0.1409362\ttotal: 5m 23s\tremaining: 4m 52s\n",
      "520:\tlearn: 0.1409095\ttotal: 5m 23s\tremaining: 4m 52s\n",
      "521:\tlearn: 0.1409076\ttotal: 5m 24s\tremaining: 4m 51s\n",
      "522:\tlearn: 0.1408754\ttotal: 5m 25s\tremaining: 4m 50s\n",
      "523:\tlearn: 0.1408635\ttotal: 5m 25s\tremaining: 4m 50s\n",
      "524:\tlearn: 0.1408493\ttotal: 5m 26s\tremaining: 4m 49s\n",
      "525:\tlearn: 0.1408440\ttotal: 5m 27s\tremaining: 4m 49s\n",
      "526:\tlearn: 0.1408305\ttotal: 5m 27s\tremaining: 4m 48s\n",
      "527:\tlearn: 0.1408290\ttotal: 5m 28s\tremaining: 4m 47s\n",
      "528:\tlearn: 0.1407966\ttotal: 5m 29s\tremaining: 4m 47s\n",
      "529:\tlearn: 0.1407939\ttotal: 5m 29s\tremaining: 4m 46s\n",
      "530:\tlearn: 0.1407705\ttotal: 5m 30s\tremaining: 4m 46s\n",
      "531:\tlearn: 0.1407363\ttotal: 5m 31s\tremaining: 4m 45s\n",
      "532:\tlearn: 0.1407092\ttotal: 5m 31s\tremaining: 4m 44s\n",
      "533:\tlearn: 0.1406934\ttotal: 5m 32s\tremaining: 4m 44s\n",
      "534:\tlearn: 0.1406697\ttotal: 5m 32s\tremaining: 4m 43s\n",
      "535:\tlearn: 0.1406579\ttotal: 5m 33s\tremaining: 4m 43s\n",
      "536:\tlearn: 0.1406503\ttotal: 5m 34s\tremaining: 4m 42s\n",
      "537:\tlearn: 0.1406461\ttotal: 5m 34s\tremaining: 4m 41s\n",
      "538:\tlearn: 0.1406230\ttotal: 5m 35s\tremaining: 4m 41s\n",
      "539:\tlearn: 0.1406010\ttotal: 5m 36s\tremaining: 4m 40s\n",
      "540:\tlearn: 0.1405743\ttotal: 5m 36s\tremaining: 4m 40s\n",
      "541:\tlearn: 0.1405457\ttotal: 5m 37s\tremaining: 4m 39s\n",
      "542:\tlearn: 0.1405454\ttotal: 5m 37s\tremaining: 4m 38s\n",
      "543:\tlearn: 0.1405227\ttotal: 5m 38s\tremaining: 4m 38s\n",
      "544:\tlearn: 0.1404999\ttotal: 5m 39s\tremaining: 4m 37s\n",
      "545:\tlearn: 0.1404724\ttotal: 5m 39s\tremaining: 4m 36s\n",
      "546:\tlearn: 0.1404535\ttotal: 5m 40s\tremaining: 4m 36s\n",
      "547:\tlearn: 0.1404438\ttotal: 5m 40s\tremaining: 4m 35s\n",
      "548:\tlearn: 0.1404346\ttotal: 5m 41s\tremaining: 4m 34s\n",
      "549:\tlearn: 0.1404141\ttotal: 5m 41s\tremaining: 4m 34s\n",
      "550:\tlearn: 0.1403909\ttotal: 5m 42s\tremaining: 4m 33s\n",
      "551:\tlearn: 0.1403781\ttotal: 5m 43s\tremaining: 4m 32s\n",
      "552:\tlearn: 0.1403645\ttotal: 5m 43s\tremaining: 4m 32s\n",
      "553:\tlearn: 0.1403434\ttotal: 5m 44s\tremaining: 4m 31s\n",
      "554:\tlearn: 0.1403322\ttotal: 5m 45s\tremaining: 4m 31s\n",
      "555:\tlearn: 0.1403022\ttotal: 5m 45s\tremaining: 4m 30s\n",
      "556:\tlearn: 0.1402864\ttotal: 5m 46s\tremaining: 4m 29s\n",
      "557:\tlearn: 0.1402749\ttotal: 5m 46s\tremaining: 4m 29s\n",
      "558:\tlearn: 0.1402662\ttotal: 5m 47s\tremaining: 4m 28s\n",
      "559:\tlearn: 0.1402390\ttotal: 5m 48s\tremaining: 4m 27s\n",
      "560:\tlearn: 0.1402256\ttotal: 5m 48s\tremaining: 4m 27s\n",
      "561:\tlearn: 0.1402184\ttotal: 5m 49s\tremaining: 4m 26s\n",
      "562:\tlearn: 0.1402106\ttotal: 5m 50s\tremaining: 4m 26s\n",
      "563:\tlearn: 0.1401610\ttotal: 5m 50s\tremaining: 4m 25s\n",
      "564:\tlearn: 0.1401401\ttotal: 5m 51s\tremaining: 4m 24s\n",
      "565:\tlearn: 0.1401329\ttotal: 5m 51s\tremaining: 4m 24s\n",
      "566:\tlearn: 0.1400819\ttotal: 5m 52s\tremaining: 4m 23s\n",
      "567:\tlearn: 0.1400700\ttotal: 5m 53s\tremaining: 4m 22s\n",
      "568:\tlearn: 0.1400378\ttotal: 5m 53s\tremaining: 4m 22s\n",
      "569:\tlearn: 0.1400239\ttotal: 5m 54s\tremaining: 4m 21s\n",
      "570:\tlearn: 0.1399953\ttotal: 5m 54s\tremaining: 4m 21s\n",
      "571:\tlearn: 0.1399683\ttotal: 5m 55s\tremaining: 4m 20s\n",
      "572:\tlearn: 0.1399466\ttotal: 5m 56s\tremaining: 4m 19s\n",
      "573:\tlearn: 0.1399335\ttotal: 5m 56s\tremaining: 4m 19s\n",
      "574:\tlearn: 0.1399262\ttotal: 5m 57s\tremaining: 4m 18s\n",
      "575:\tlearn: 0.1399031\ttotal: 5m 57s\tremaining: 4m 17s\n",
      "576:\tlearn: 0.1398889\ttotal: 5m 58s\tremaining: 4m 17s\n",
      "577:\tlearn: 0.1398617\ttotal: 5m 59s\tremaining: 4m 16s\n",
      "578:\tlearn: 0.1398502\ttotal: 5m 59s\tremaining: 4m 16s\n",
      "579:\tlearn: 0.1398244\ttotal: 6m\tremaining: 4m 15s\n",
      "580:\tlearn: 0.1398063\ttotal: 6m 1s\tremaining: 4m 14s\n",
      "581:\tlearn: 0.1397921\ttotal: 6m 1s\tremaining: 4m 14s\n",
      "582:\tlearn: 0.1397690\ttotal: 6m 2s\tremaining: 4m 13s\n",
      "583:\tlearn: 0.1397546\ttotal: 6m 2s\tremaining: 4m 12s\n",
      "584:\tlearn: 0.1397319\ttotal: 6m 3s\tremaining: 4m 12s\n",
      "585:\tlearn: 0.1397176\ttotal: 6m 4s\tremaining: 4m 11s\n",
      "586:\tlearn: 0.1396888\ttotal: 6m 4s\tremaining: 4m 10s\n",
      "587:\tlearn: 0.1396856\ttotal: 6m 5s\tremaining: 4m 10s\n",
      "588:\tlearn: 0.1396674\ttotal: 6m 5s\tremaining: 4m 9s\n",
      "589:\tlearn: 0.1396627\ttotal: 6m 6s\tremaining: 4m 8s\n",
      "590:\tlearn: 0.1396473\ttotal: 6m 6s\tremaining: 4m 8s\n",
      "591:\tlearn: 0.1396273\ttotal: 6m 7s\tremaining: 4m 7s\n",
      "592:\tlearn: 0.1396028\ttotal: 6m 8s\tremaining: 4m 7s\n",
      "593:\tlearn: 0.1395983\ttotal: 6m 8s\tremaining: 4m 6s\n",
      "594:\tlearn: 0.1395893\ttotal: 6m 9s\tremaining: 4m 5s\n",
      "595:\tlearn: 0.1395789\ttotal: 6m 9s\tremaining: 4m 5s\n",
      "596:\tlearn: 0.1395494\ttotal: 6m 10s\tremaining: 4m 4s\n",
      "597:\tlearn: 0.1395248\ttotal: 6m 10s\tremaining: 4m 3s\n",
      "598:\tlearn: 0.1395013\ttotal: 6m 11s\tremaining: 4m 3s\n",
      "599:\tlearn: 0.1394700\ttotal: 6m 12s\tremaining: 4m 2s\n",
      "600:\tlearn: 0.1394552\ttotal: 6m 12s\tremaining: 4m 1s\n",
      "601:\tlearn: 0.1394316\ttotal: 6m 13s\tremaining: 4m 1s\n",
      "602:\tlearn: 0.1393958\ttotal: 6m 13s\tremaining: 4m\n",
      "603:\tlearn: 0.1393805\ttotal: 6m 14s\tremaining: 3m 59s\n",
      "604:\tlearn: 0.1393623\ttotal: 6m 15s\tremaining: 3m 59s\n",
      "605:\tlearn: 0.1393454\ttotal: 6m 15s\tremaining: 3m 58s\n",
      "606:\tlearn: 0.1393137\ttotal: 6m 16s\tremaining: 3m 58s\n",
      "607:\tlearn: 0.1392873\ttotal: 6m 17s\tremaining: 3m 57s\n",
      "608:\tlearn: 0.1392802\ttotal: 6m 18s\tremaining: 3m 57s\n",
      "609:\tlearn: 0.1392607\ttotal: 6m 18s\tremaining: 3m 56s\n",
      "610:\tlearn: 0.1392602\ttotal: 6m 19s\tremaining: 3m 56s\n",
      "611:\tlearn: 0.1392365\ttotal: 6m 20s\tremaining: 3m 55s\n",
      "612:\tlearn: 0.1392142\ttotal: 6m 21s\tremaining: 3m 55s\n",
      "613:\tlearn: 0.1391987\ttotal: 6m 21s\tremaining: 3m 54s\n",
      "614:\tlearn: 0.1391886\ttotal: 6m 22s\tremaining: 3m 54s\n",
      "615:\tlearn: 0.1391641\ttotal: 6m 23s\tremaining: 3m 53s\n",
      "616:\tlearn: 0.1391233\ttotal: 6m 24s\tremaining: 3m 53s\n",
      "617:\tlearn: 0.1391045\ttotal: 6m 25s\tremaining: 3m 52s\n",
      "618:\tlearn: 0.1390858\ttotal: 6m 27s\tremaining: 3m 52s\n",
      "619:\tlearn: 0.1390808\ttotal: 6m 27s\tremaining: 3m 52s\n",
      "620:\tlearn: 0.1390649\ttotal: 6m 28s\tremaining: 3m 51s\n",
      "621:\tlearn: 0.1390436\ttotal: 6m 30s\tremaining: 3m 51s\n",
      "622:\tlearn: 0.1390380\ttotal: 6m 31s\tremaining: 3m 51s\n",
      "623:\tlearn: 0.1390099\ttotal: 6m 32s\tremaining: 3m 51s\n",
      "624:\tlearn: 0.1389853\ttotal: 6m 34s\tremaining: 3m 50s\n",
      "625:\tlearn: 0.1389852\ttotal: 6m 35s\tremaining: 3m 50s\n",
      "626:\tlearn: 0.1389742\ttotal: 6m 37s\tremaining: 3m 50s\n",
      "627:\tlearn: 0.1389530\ttotal: 6m 38s\tremaining: 3m 50s\n",
      "628:\tlearn: 0.1389446\ttotal: 6m 39s\tremaining: 3m 50s\n",
      "629:\tlearn: 0.1389369\ttotal: 6m 41s\tremaining: 3m 49s\n",
      "630:\tlearn: 0.1388928\ttotal: 6m 42s\tremaining: 3m 49s\n",
      "631:\tlearn: 0.1388779\ttotal: 6m 43s\tremaining: 3m 49s\n",
      "632:\tlearn: 0.1388652\ttotal: 6m 44s\tremaining: 3m 48s\n",
      "633:\tlearn: 0.1388446\ttotal: 6m 46s\tremaining: 3m 48s\n",
      "634:\tlearn: 0.1388365\ttotal: 6m 47s\tremaining: 3m 48s\n",
      "635:\tlearn: 0.1388105\ttotal: 6m 48s\tremaining: 3m 48s\n",
      "636:\tlearn: 0.1387975\ttotal: 6m 49s\tremaining: 3m 47s\n",
      "637:\tlearn: 0.1387968\ttotal: 6m 51s\tremaining: 3m 47s\n",
      "638:\tlearn: 0.1387821\ttotal: 6m 51s\tremaining: 3m 46s\n",
      "639:\tlearn: 0.1387616\ttotal: 6m 52s\tremaining: 3m 46s\n",
      "640:\tlearn: 0.1387557\ttotal: 6m 53s\tremaining: 3m 45s\n",
      "641:\tlearn: 0.1387293\ttotal: 6m 54s\tremaining: 3m 45s\n",
      "642:\tlearn: 0.1387154\ttotal: 6m 55s\tremaining: 3m 44s\n",
      "643:\tlearn: 0.1387133\ttotal: 6m 55s\tremaining: 3m 44s\n",
      "644:\tlearn: 0.1387024\ttotal: 6m 56s\tremaining: 3m 43s\n",
      "645:\tlearn: 0.1386776\ttotal: 6m 57s\tremaining: 3m 42s\n",
      "646:\tlearn: 0.1386553\ttotal: 6m 58s\tremaining: 3m 42s\n",
      "647:\tlearn: 0.1386366\ttotal: 6m 59s\tremaining: 3m 42s\n",
      "648:\tlearn: 0.1386169\ttotal: 7m\tremaining: 3m 41s\n",
      "649:\tlearn: 0.1385758\ttotal: 7m\tremaining: 3m 40s\n",
      "650:\tlearn: 0.1385464\ttotal: 7m 1s\tremaining: 3m 40s\n",
      "651:\tlearn: 0.1385000\ttotal: 7m 2s\tremaining: 3m 39s\n",
      "652:\tlearn: 0.1384564\ttotal: 7m 3s\tremaining: 3m 39s\n",
      "653:\tlearn: 0.1384350\ttotal: 7m 4s\tremaining: 3m 38s\n",
      "654:\tlearn: 0.1384151\ttotal: 7m 4s\tremaining: 3m 38s\n",
      "655:\tlearn: 0.1384044\ttotal: 7m 5s\tremaining: 3m 37s\n",
      "656:\tlearn: 0.1383964\ttotal: 7m 6s\tremaining: 3m 36s\n",
      "657:\tlearn: 0.1383797\ttotal: 7m 7s\tremaining: 3m 36s\n",
      "658:\tlearn: 0.1383777\ttotal: 7m 8s\tremaining: 3m 35s\n",
      "659:\tlearn: 0.1383664\ttotal: 7m 8s\tremaining: 3m 35s\n",
      "660:\tlearn: 0.1383547\ttotal: 7m 9s\tremaining: 3m 34s\n",
      "661:\tlearn: 0.1383442\ttotal: 7m 10s\tremaining: 3m 33s\n",
      "662:\tlearn: 0.1383319\ttotal: 7m 11s\tremaining: 3m 33s\n",
      "663:\tlearn: 0.1383182\ttotal: 7m 12s\tremaining: 3m 32s\n",
      "664:\tlearn: 0.1383019\ttotal: 7m 13s\tremaining: 3m 32s\n",
      "665:\tlearn: 0.1382945\ttotal: 7m 14s\tremaining: 3m 31s\n",
      "666:\tlearn: 0.1382720\ttotal: 7m 15s\tremaining: 3m 31s\n",
      "667:\tlearn: 0.1382457\ttotal: 7m 16s\tremaining: 3m 31s\n",
      "668:\tlearn: 0.1382274\ttotal: 7m 17s\tremaining: 3m 30s\n",
      "669:\tlearn: 0.1382060\ttotal: 7m 18s\tremaining: 3m 30s\n",
      "670:\tlearn: 0.1382006\ttotal: 7m 19s\tremaining: 3m 29s\n",
      "671:\tlearn: 0.1381924\ttotal: 7m 20s\tremaining: 3m 28s\n",
      "672:\tlearn: 0.1381636\ttotal: 7m 21s\tremaining: 3m 28s\n",
      "673:\tlearn: 0.1381430\ttotal: 7m 22s\tremaining: 3m 28s\n",
      "674:\tlearn: 0.1381249\ttotal: 7m 23s\tremaining: 3m 27s\n",
      "675:\tlearn: 0.1381043\ttotal: 7m 24s\tremaining: 3m 27s\n",
      "676:\tlearn: 0.1380965\ttotal: 7m 25s\tremaining: 3m 26s\n",
      "677:\tlearn: 0.1380895\ttotal: 7m 26s\tremaining: 3m 25s\n",
      "678:\tlearn: 0.1380857\ttotal: 7m 26s\tremaining: 3m 25s\n",
      "679:\tlearn: 0.1380805\ttotal: 7m 27s\tremaining: 3m 24s\n",
      "680:\tlearn: 0.1380634\ttotal: 7m 28s\tremaining: 3m 24s\n",
      "681:\tlearn: 0.1380307\ttotal: 7m 29s\tremaining: 3m 23s\n",
      "682:\tlearn: 0.1380165\ttotal: 7m 33s\tremaining: 3m 24s\n",
      "683:\tlearn: 0.1380132\ttotal: 7m 35s\tremaining: 3m 24s\n",
      "684:\tlearn: 0.1379995\ttotal: 7m 37s\tremaining: 3m 24s\n",
      "685:\tlearn: 0.1379845\ttotal: 7m 38s\tremaining: 3m 23s\n",
      "686:\tlearn: 0.1379760\ttotal: 7m 39s\tremaining: 3m 23s\n",
      "687:\tlearn: 0.1379698\ttotal: 7m 40s\tremaining: 3m 22s\n",
      "688:\tlearn: 0.1379651\ttotal: 7m 41s\tremaining: 3m 22s\n",
      "689:\tlearn: 0.1379573\ttotal: 7m 41s\tremaining: 3m 21s\n",
      "690:\tlearn: 0.1379423\ttotal: 7m 42s\tremaining: 3m 20s\n",
      "691:\tlearn: 0.1379242\ttotal: 7m 43s\tremaining: 3m 20s\n",
      "692:\tlearn: 0.1378812\ttotal: 7m 44s\tremaining: 3m 19s\n",
      "693:\tlearn: 0.1378757\ttotal: 7m 45s\tremaining: 3m 19s\n",
      "694:\tlearn: 0.1378576\ttotal: 7m 46s\tremaining: 3m 18s\n",
      "695:\tlearn: 0.1378340\ttotal: 8m 11s\tremaining: 3m 28s\n",
      "696:\tlearn: 0.1378035\ttotal: 8m 12s\tremaining: 3m 27s\n",
      "697:\tlearn: 0.1377929\ttotal: 8m 13s\tremaining: 3m 27s\n",
      "698:\tlearn: 0.1377843\ttotal: 8m 14s\tremaining: 3m 26s\n",
      "699:\tlearn: 0.1377637\ttotal: 8m 15s\tremaining: 3m 25s\n",
      "700:\tlearn: 0.1377529\ttotal: 8m 15s\tremaining: 3m 25s\n",
      "701:\tlearn: 0.1377374\ttotal: 8m 16s\tremaining: 3m 24s\n",
      "702:\tlearn: 0.1377121\ttotal: 8m 18s\tremaining: 3m 24s\n",
      "703:\tlearn: 0.1376861\ttotal: 8m 19s\tremaining: 3m 23s\n",
      "704:\tlearn: 0.1376676\ttotal: 8m 23s\tremaining: 3m 24s\n",
      "705:\tlearn: 0.1376380\ttotal: 8m 25s\tremaining: 3m 24s\n",
      "706:\tlearn: 0.1376048\ttotal: 8m 27s\tremaining: 3m 23s\n",
      "707:\tlearn: 0.1375977\ttotal: 8m 28s\tremaining: 3m 23s\n",
      "708:\tlearn: 0.1375757\ttotal: 8m 29s\tremaining: 3m 22s\n",
      "709:\tlearn: 0.1375601\ttotal: 8m 30s\tremaining: 3m 21s\n",
      "710:\tlearn: 0.1375587\ttotal: 8m 30s\tremaining: 3m 21s\n",
      "711:\tlearn: 0.1375544\ttotal: 8m 31s\tremaining: 3m 20s\n",
      "712:\tlearn: 0.1375287\ttotal: 8m 32s\tremaining: 3m 19s\n",
      "713:\tlearn: 0.1375266\ttotal: 8m 34s\tremaining: 3m 19s\n",
      "714:\tlearn: 0.1375163\ttotal: 8m 36s\tremaining: 3m 19s\n",
      "715:\tlearn: 0.1375127\ttotal: 8m 37s\tremaining: 3m 18s\n",
      "716:\tlearn: 0.1374913\ttotal: 8m 37s\tremaining: 3m 17s\n",
      "717:\tlearn: 0.1374766\ttotal: 8m 38s\tremaining: 3m 17s\n",
      "718:\tlearn: 0.1374725\ttotal: 8m 39s\tremaining: 3m 16s\n",
      "719:\tlearn: 0.1374509\ttotal: 8m 40s\tremaining: 3m 15s\n",
      "720:\tlearn: 0.1374273\ttotal: 8m 41s\tremaining: 3m 15s\n",
      "721:\tlearn: 0.1374068\ttotal: 8m 42s\tremaining: 3m 14s\n",
      "722:\tlearn: 0.1373990\ttotal: 8m 43s\tremaining: 3m 13s\n",
      "723:\tlearn: 0.1373748\ttotal: 8m 43s\tremaining: 3m 13s\n",
      "724:\tlearn: 0.1373717\ttotal: 8m 44s\tremaining: 3m 12s\n",
      "725:\tlearn: 0.1373533\ttotal: 8m 45s\tremaining: 3m 11s\n",
      "726:\tlearn: 0.1373476\ttotal: 8m 46s\tremaining: 3m 11s\n",
      "727:\tlearn: 0.1373212\ttotal: 8m 47s\tremaining: 3m 10s\n",
      "728:\tlearn: 0.1373059\ttotal: 8m 48s\tremaining: 3m 9s\n",
      "729:\tlearn: 0.1373049\ttotal: 8m 48s\tremaining: 3m 9s\n",
      "730:\tlearn: 0.1372717\ttotal: 8m 49s\tremaining: 3m 8s\n",
      "731:\tlearn: 0.1372577\ttotal: 8m 50s\tremaining: 3m 7s\n",
      "732:\tlearn: 0.1372560\ttotal: 8m 51s\tremaining: 3m 6s\n",
      "733:\tlearn: 0.1372199\ttotal: 8m 51s\tremaining: 3m 6s\n",
      "734:\tlearn: 0.1371984\ttotal: 8m 52s\tremaining: 3m 5s\n",
      "735:\tlearn: 0.1371852\ttotal: 8m 53s\tremaining: 3m 4s\n",
      "736:\tlearn: 0.1371808\ttotal: 8m 53s\tremaining: 3m 3s\n",
      "737:\tlearn: 0.1371645\ttotal: 8m 54s\tremaining: 3m 3s\n",
      "738:\tlearn: 0.1371412\ttotal: 8m 55s\tremaining: 3m 2s\n",
      "739:\tlearn: 0.1371402\ttotal: 8m 55s\tremaining: 3m 1s\n",
      "740:\tlearn: 0.1371165\ttotal: 8m 56s\tremaining: 3m\n",
      "741:\tlearn: 0.1371024\ttotal: 8m 57s\tremaining: 3m\n",
      "742:\tlearn: 0.1370949\ttotal: 8m 57s\tremaining: 2m 59s\n",
      "743:\tlearn: 0.1370768\ttotal: 8m 58s\tremaining: 2m 58s\n",
      "744:\tlearn: 0.1370570\ttotal: 8m 59s\tremaining: 2m 58s\n",
      "745:\tlearn: 0.1370454\ttotal: 8m 59s\tremaining: 2m 57s\n",
      "746:\tlearn: 0.1370050\ttotal: 9m\tremaining: 2m 56s\n",
      "747:\tlearn: 0.1369912\ttotal: 9m 1s\tremaining: 2m 55s\n",
      "748:\tlearn: 0.1369632\ttotal: 9m 1s\tremaining: 2m 55s\n",
      "749:\tlearn: 0.1369566\ttotal: 9m 2s\tremaining: 2m 54s\n",
      "750:\tlearn: 0.1369431\ttotal: 9m 3s\tremaining: 2m 53s\n",
      "751:\tlearn: 0.1369140\ttotal: 9m 3s\tremaining: 2m 52s\n",
      "752:\tlearn: 0.1368986\ttotal: 9m 4s\tremaining: 2m 52s\n",
      "753:\tlearn: 0.1368869\ttotal: 9m 5s\tremaining: 2m 51s\n",
      "754:\tlearn: 0.1368807\ttotal: 9m 6s\tremaining: 2m 50s\n",
      "755:\tlearn: 0.1368710\ttotal: 9m 7s\tremaining: 2m 50s\n",
      "756:\tlearn: 0.1368594\ttotal: 9m 7s\tremaining: 2m 49s\n",
      "757:\tlearn: 0.1368478\ttotal: 9m 8s\tremaining: 2m 48s\n",
      "758:\tlearn: 0.1368232\ttotal: 9m 9s\tremaining: 2m 47s\n",
      "759:\tlearn: 0.1368032\ttotal: 9m 10s\tremaining: 2m 47s\n",
      "760:\tlearn: 0.1367851\ttotal: 9m 14s\tremaining: 2m 47s\n",
      "761:\tlearn: 0.1367768\ttotal: 9m 15s\tremaining: 2m 47s\n",
      "762:\tlearn: 0.1367595\ttotal: 9m 17s\tremaining: 2m 46s\n",
      "763:\tlearn: 0.1367452\ttotal: 9m 18s\tremaining: 2m 46s\n",
      "764:\tlearn: 0.1367262\ttotal: 9m 19s\tremaining: 2m 45s\n",
      "765:\tlearn: 0.1367235\ttotal: 9m 20s\tremaining: 2m 44s\n",
      "766:\tlearn: 0.1367079\ttotal: 9m 21s\tremaining: 2m 44s\n",
      "767:\tlearn: 0.1366923\ttotal: 9m 22s\tremaining: 2m 43s\n",
      "768:\tlearn: 0.1366631\ttotal: 9m 23s\tremaining: 2m 42s\n",
      "769:\tlearn: 0.1366629\ttotal: 9m 24s\tremaining: 2m 41s\n",
      "770:\tlearn: 0.1366473\ttotal: 9m 25s\tremaining: 2m 41s\n",
      "771:\tlearn: 0.1366421\ttotal: 9m 25s\tremaining: 2m 40s\n",
      "772:\tlearn: 0.1366205\ttotal: 9m 27s\tremaining: 2m 39s\n",
      "773:\tlearn: 0.1365925\ttotal: 9m 28s\tremaining: 2m 39s\n",
      "774:\tlearn: 0.1365682\ttotal: 9m 29s\tremaining: 2m 38s\n",
      "775:\tlearn: 0.1365401\ttotal: 9m 29s\tremaining: 2m 37s\n",
      "776:\tlearn: 0.1365300\ttotal: 9m 30s\tremaining: 2m 37s\n",
      "777:\tlearn: 0.1365229\ttotal: 9m 31s\tremaining: 2m 36s\n",
      "778:\tlearn: 0.1365055\ttotal: 9m 32s\tremaining: 2m 35s\n",
      "779:\tlearn: 0.1364885\ttotal: 9m 33s\tremaining: 2m 35s\n",
      "780:\tlearn: 0.1364730\ttotal: 9m 34s\tremaining: 2m 34s\n",
      "781:\tlearn: 0.1364519\ttotal: 9m 35s\tremaining: 2m 33s\n",
      "782:\tlearn: 0.1364393\ttotal: 9m 36s\tremaining: 2m 33s\n",
      "783:\tlearn: 0.1364251\ttotal: 9m 37s\tremaining: 2m 32s\n",
      "784:\tlearn: 0.1364142\ttotal: 9m 38s\tremaining: 2m 31s\n",
      "785:\tlearn: 0.1363929\ttotal: 9m 39s\tremaining: 2m 31s\n",
      "786:\tlearn: 0.1363851\ttotal: 9m 40s\tremaining: 2m 30s\n",
      "787:\tlearn: 0.1363670\ttotal: 9m 40s\tremaining: 2m 29s\n",
      "788:\tlearn: 0.1363414\ttotal: 9m 41s\tremaining: 2m 28s\n",
      "789:\tlearn: 0.1363150\ttotal: 9m 42s\tremaining: 2m 28s\n",
      "790:\tlearn: 0.1362855\ttotal: 9m 43s\tremaining: 2m 27s\n",
      "791:\tlearn: 0.1362730\ttotal: 9m 44s\tremaining: 2m 26s\n",
      "792:\tlearn: 0.1362486\ttotal: 9m 45s\tremaining: 2m 26s\n",
      "793:\tlearn: 0.1362319\ttotal: 9m 46s\tremaining: 2m 25s\n",
      "794:\tlearn: 0.1362316\ttotal: 9m 46s\tremaining: 2m 24s\n",
      "795:\tlearn: 0.1362046\ttotal: 9m 47s\tremaining: 2m 23s\n",
      "796:\tlearn: 0.1361949\ttotal: 9m 48s\tremaining: 2m 23s\n",
      "797:\tlearn: 0.1361755\ttotal: 9m 49s\tremaining: 2m 22s\n",
      "798:\tlearn: 0.1361579\ttotal: 9m 50s\tremaining: 2m 21s\n",
      "799:\tlearn: 0.1361473\ttotal: 9m 50s\tremaining: 2m 21s\n",
      "800:\tlearn: 0.1361359\ttotal: 9m 51s\tremaining: 2m 20s\n",
      "801:\tlearn: 0.1361301\ttotal: 9m 52s\tremaining: 2m 19s\n",
      "802:\tlearn: 0.1361144\ttotal: 9m 53s\tremaining: 2m 18s\n",
      "803:\tlearn: 0.1361041\ttotal: 9m 54s\tremaining: 2m 18s\n",
      "804:\tlearn: 0.1360835\ttotal: 9m 55s\tremaining: 2m 17s\n",
      "805:\tlearn: 0.1360720\ttotal: 9m 56s\tremaining: 2m 16s\n",
      "806:\tlearn: 0.1360390\ttotal: 9m 56s\tremaining: 2m 16s\n",
      "807:\tlearn: 0.1360198\ttotal: 9m 57s\tremaining: 2m 15s\n",
      "808:\tlearn: 0.1360032\ttotal: 9m 58s\tremaining: 2m 14s\n",
      "809:\tlearn: 0.1359970\ttotal: 9m 59s\tremaining: 2m 13s\n",
      "810:\tlearn: 0.1359695\ttotal: 10m\tremaining: 2m 13s\n",
      "811:\tlearn: 0.1359605\ttotal: 10m 1s\tremaining: 2m 12s\n",
      "812:\tlearn: 0.1359544\ttotal: 10m 1s\tremaining: 2m 11s\n",
      "813:\tlearn: 0.1359403\ttotal: 10m 2s\tremaining: 2m 11s\n",
      "814:\tlearn: 0.1359216\ttotal: 10m 3s\tremaining: 2m 10s\n",
      "815:\tlearn: 0.1358997\ttotal: 10m 4s\tremaining: 2m 9s\n",
      "816:\tlearn: 0.1358922\ttotal: 10m 4s\tremaining: 2m 8s\n",
      "817:\tlearn: 0.1358778\ttotal: 10m 5s\tremaining: 2m 8s\n",
      "818:\tlearn: 0.1358730\ttotal: 10m 6s\tremaining: 2m 7s\n",
      "819:\tlearn: 0.1358580\ttotal: 10m 7s\tremaining: 2m 6s\n",
      "820:\tlearn: 0.1358499\ttotal: 10m 8s\tremaining: 2m 6s\n",
      "821:\tlearn: 0.1358365\ttotal: 10m 9s\tremaining: 2m 5s\n",
      "822:\tlearn: 0.1358285\ttotal: 10m 10s\tremaining: 2m 4s\n",
      "823:\tlearn: 0.1358093\ttotal: 10m 11s\tremaining: 2m 3s\n",
      "824:\tlearn: 0.1358018\ttotal: 10m 11s\tremaining: 2m 3s\n",
      "825:\tlearn: 0.1357950\ttotal: 10m 12s\tremaining: 2m 2s\n",
      "826:\tlearn: 0.1357791\ttotal: 10m 13s\tremaining: 2m 1s\n",
      "827:\tlearn: 0.1357770\ttotal: 10m 14s\tremaining: 2m\n",
      "828:\tlearn: 0.1357585\ttotal: 10m 15s\tremaining: 2m\n",
      "829:\tlearn: 0.1357391\ttotal: 10m 16s\tremaining: 1m 59s\n",
      "830:\tlearn: 0.1357136\ttotal: 10m 16s\tremaining: 1m 58s\n",
      "831:\tlearn: 0.1356973\ttotal: 10m 17s\tremaining: 1m 57s\n",
      "832:\tlearn: 0.1356950\ttotal: 10m 18s\tremaining: 1m 57s\n",
      "833:\tlearn: 0.1356896\ttotal: 10m 18s\tremaining: 1m 56s\n",
      "834:\tlearn: 0.1356659\ttotal: 10m 19s\tremaining: 1m 55s\n",
      "835:\tlearn: 0.1356519\ttotal: 10m 20s\tremaining: 1m 55s\n",
      "836:\tlearn: 0.1356302\ttotal: 10m 21s\tremaining: 1m 54s\n",
      "837:\tlearn: 0.1356093\ttotal: 10m 22s\tremaining: 1m 53s\n",
      "838:\tlearn: 0.1355946\ttotal: 10m 23s\tremaining: 1m 52s\n",
      "839:\tlearn: 0.1355902\ttotal: 10m 24s\tremaining: 1m 52s\n",
      "840:\tlearn: 0.1355784\ttotal: 10m 25s\tremaining: 1m 51s\n",
      "841:\tlearn: 0.1355537\ttotal: 10m 26s\tremaining: 1m 50s\n",
      "842:\tlearn: 0.1355407\ttotal: 10m 27s\tremaining: 1m 50s\n",
      "843:\tlearn: 0.1355239\ttotal: 10m 27s\tremaining: 1m 49s\n",
      "844:\tlearn: 0.1355039\ttotal: 10m 28s\tremaining: 1m 48s\n",
      "845:\tlearn: 0.1354980\ttotal: 10m 29s\tremaining: 1m 47s\n",
      "846:\tlearn: 0.1354847\ttotal: 10m 30s\tremaining: 1m 47s\n",
      "847:\tlearn: 0.1354763\ttotal: 10m 31s\tremaining: 1m 46s\n",
      "848:\tlearn: 0.1354414\ttotal: 10m 32s\tremaining: 1m 45s\n",
      "849:\tlearn: 0.1354106\ttotal: 10m 33s\tremaining: 1m 45s\n",
      "850:\tlearn: 0.1353947\ttotal: 10m 34s\tremaining: 1m 44s\n",
      "851:\tlearn: 0.1353783\ttotal: 10m 34s\tremaining: 1m 43s\n",
      "852:\tlearn: 0.1353729\ttotal: 10m 35s\tremaining: 1m 42s\n",
      "853:\tlearn: 0.1353530\ttotal: 10m 36s\tremaining: 1m 42s\n",
      "854:\tlearn: 0.1353414\ttotal: 10m 37s\tremaining: 1m 41s\n",
      "855:\tlearn: 0.1353355\ttotal: 10m 37s\tremaining: 1m 40s\n",
      "856:\tlearn: 0.1353333\ttotal: 10m 38s\tremaining: 1m 39s\n",
      "857:\tlearn: 0.1353195\ttotal: 10m 39s\tremaining: 1m 39s\n",
      "858:\tlearn: 0.1353017\ttotal: 10m 40s\tremaining: 1m 38s\n",
      "859:\tlearn: 0.1352975\ttotal: 10m 41s\tremaining: 1m 37s\n",
      "860:\tlearn: 0.1352831\ttotal: 10m 42s\tremaining: 1m 36s\n",
      "861:\tlearn: 0.1352693\ttotal: 10m 43s\tremaining: 1m 36s\n",
      "862:\tlearn: 0.1352613\ttotal: 10m 43s\tremaining: 1m 35s\n",
      "863:\tlearn: 0.1352461\ttotal: 10m 44s\tremaining: 1m 34s\n",
      "864:\tlearn: 0.1352346\ttotal: 10m 45s\tremaining: 1m 33s\n",
      "865:\tlearn: 0.1352108\ttotal: 10m 45s\tremaining: 1m 33s\n",
      "866:\tlearn: 0.1351994\ttotal: 10m 46s\tremaining: 1m 32s\n",
      "867:\tlearn: 0.1351983\ttotal: 10m 47s\tremaining: 1m 31s\n",
      "868:\tlearn: 0.1351771\ttotal: 10m 47s\tremaining: 1m 30s\n",
      "869:\tlearn: 0.1351642\ttotal: 10m 48s\tremaining: 1m 30s\n",
      "870:\tlearn: 0.1351474\ttotal: 10m 49s\tremaining: 1m 29s\n",
      "871:\tlearn: 0.1351335\ttotal: 10m 50s\tremaining: 1m 28s\n",
      "872:\tlearn: 0.1351323\ttotal: 10m 50s\tremaining: 1m 27s\n",
      "873:\tlearn: 0.1351146\ttotal: 10m 52s\tremaining: 1m 27s\n",
      "874:\tlearn: 0.1351133\ttotal: 10m 52s\tremaining: 1m 26s\n",
      "875:\tlearn: 0.1351034\ttotal: 10m 53s\tremaining: 1m 25s\n",
      "876:\tlearn: 0.1350813\ttotal: 10m 54s\tremaining: 1m 25s\n",
      "877:\tlearn: 0.1350501\ttotal: 10m 55s\tremaining: 1m 24s\n",
      "878:\tlearn: 0.1350465\ttotal: 10m 55s\tremaining: 1m 23s\n",
      "879:\tlearn: 0.1350345\ttotal: 10m 56s\tremaining: 1m 22s\n",
      "880:\tlearn: 0.1350291\ttotal: 10m 57s\tremaining: 1m 22s\n",
      "881:\tlearn: 0.1350090\ttotal: 10m 58s\tremaining: 1m 21s\n",
      "882:\tlearn: 0.1349904\ttotal: 10m 58s\tremaining: 1m 20s\n",
      "883:\tlearn: 0.1349787\ttotal: 10m 59s\tremaining: 1m 19s\n",
      "884:\tlearn: 0.1349634\ttotal: 11m\tremaining: 1m 19s\n",
      "885:\tlearn: 0.1349327\ttotal: 11m 1s\tremaining: 1m 18s\n",
      "886:\tlearn: 0.1349123\ttotal: 11m 2s\tremaining: 1m 17s\n",
      "887:\tlearn: 0.1349074\ttotal: 11m 3s\tremaining: 1m 16s\n",
      "888:\tlearn: 0.1348941\ttotal: 11m 3s\tremaining: 1m 16s\n",
      "889:\tlearn: 0.1348856\ttotal: 11m 4s\tremaining: 1m 15s\n",
      "890:\tlearn: 0.1348833\ttotal: 11m 5s\tremaining: 1m 14s\n",
      "891:\tlearn: 0.1348736\ttotal: 11m 6s\tremaining: 1m 13s\n",
      "892:\tlearn: 0.1348636\ttotal: 11m 6s\tremaining: 1m 13s\n",
      "893:\tlearn: 0.1348542\ttotal: 11m 7s\tremaining: 1m 12s\n",
      "894:\tlearn: 0.1348454\ttotal: 11m 8s\tremaining: 1m 11s\n",
      "895:\tlearn: 0.1348349\ttotal: 11m 9s\tremaining: 1m 10s\n",
      "896:\tlearn: 0.1347904\ttotal: 11m 9s\tremaining: 1m 10s\n",
      "897:\tlearn: 0.1347782\ttotal: 11m 10s\tremaining: 1m 9s\n",
      "898:\tlearn: 0.1347617\ttotal: 11m 11s\tremaining: 1m 8s\n",
      "899:\tlearn: 0.1347390\ttotal: 11m 12s\tremaining: 1m 7s\n",
      "900:\tlearn: 0.1347188\ttotal: 11m 13s\tremaining: 1m 7s\n",
      "901:\tlearn: 0.1346989\ttotal: 11m 13s\tremaining: 1m 6s\n",
      "902:\tlearn: 0.1346805\ttotal: 11m 14s\tremaining: 1m 5s\n",
      "903:\tlearn: 0.1346701\ttotal: 11m 15s\tremaining: 1m 4s\n",
      "904:\tlearn: 0.1346598\ttotal: 11m 15s\tremaining: 1m 4s\n",
      "905:\tlearn: 0.1346530\ttotal: 11m 16s\tremaining: 1m 3s\n",
      "906:\tlearn: 0.1346397\ttotal: 11m 17s\tremaining: 1m 2s\n",
      "907:\tlearn: 0.1346272\ttotal: 11m 18s\tremaining: 1m 2s\n",
      "908:\tlearn: 0.1346218\ttotal: 11m 19s\tremaining: 1m 1s\n",
      "909:\tlearn: 0.1346155\ttotal: 11m 19s\tremaining: 1m\n",
      "910:\tlearn: 0.1345960\ttotal: 11m 20s\tremaining: 59.8s\n",
      "911:\tlearn: 0.1345653\ttotal: 11m 21s\tremaining: 59.1s\n",
      "912:\tlearn: 0.1345576\ttotal: 11m 22s\tremaining: 58.3s\n",
      "913:\tlearn: 0.1345553\ttotal: 11m 23s\tremaining: 57.6s\n",
      "914:\tlearn: 0.1345425\ttotal: 11m 24s\tremaining: 56.8s\n",
      "915:\tlearn: 0.1345283\ttotal: 11m 25s\tremaining: 56.1s\n",
      "916:\tlearn: 0.1345188\ttotal: 11m 25s\tremaining: 55.4s\n",
      "917:\tlearn: 0.1345007\ttotal: 11m 26s\tremaining: 54.6s\n",
      "918:\tlearn: 0.1344867\ttotal: 11m 27s\tremaining: 53.9s\n",
      "919:\tlearn: 0.1344687\ttotal: 11m 28s\tremaining: 53.1s\n",
      "920:\tlearn: 0.1344610\ttotal: 11m 28s\tremaining: 52.4s\n",
      "921:\tlearn: 0.1344596\ttotal: 11m 29s\tremaining: 51.6s\n",
      "922:\tlearn: 0.1344439\ttotal: 11m 30s\tremaining: 50.9s\n",
      "923:\tlearn: 0.1344178\ttotal: 11m 30s\tremaining: 50.1s\n",
      "924:\tlearn: 0.1344103\ttotal: 11m 31s\tremaining: 49.3s\n",
      "925:\tlearn: 0.1343940\ttotal: 11m 32s\tremaining: 48.6s\n",
      "926:\tlearn: 0.1343653\ttotal: 11m 32s\tremaining: 47.8s\n",
      "927:\tlearn: 0.1343485\ttotal: 11m 33s\tremaining: 47.1s\n",
      "928:\tlearn: 0.1343302\ttotal: 11m 34s\tremaining: 46.3s\n",
      "929:\tlearn: 0.1343207\ttotal: 11m 35s\tremaining: 45.6s\n",
      "930:\tlearn: 0.1343158\ttotal: 11m 35s\tremaining: 44.8s\n",
      "931:\tlearn: 0.1342985\ttotal: 11m 36s\tremaining: 44.1s\n",
      "932:\tlearn: 0.1342783\ttotal: 11m 37s\tremaining: 43.3s\n",
      "933:\tlearn: 0.1342646\ttotal: 11m 37s\tremaining: 42.6s\n",
      "934:\tlearn: 0.1342590\ttotal: 11m 38s\tremaining: 41.8s\n",
      "935:\tlearn: 0.1342535\ttotal: 11m 39s\tremaining: 41.1s\n",
      "936:\tlearn: 0.1342299\ttotal: 11m 40s\tremaining: 40.4s\n",
      "937:\tlearn: 0.1342115\ttotal: 11m 40s\tremaining: 39.6s\n",
      "938:\tlearn: 0.1341977\ttotal: 11m 41s\tremaining: 38.9s\n",
      "939:\tlearn: 0.1341785\ttotal: 11m 42s\tremaining: 38.1s\n",
      "940:\tlearn: 0.1341498\ttotal: 11m 43s\tremaining: 37.4s\n",
      "941:\tlearn: 0.1341438\ttotal: 11m 43s\tremaining: 36.6s\n",
      "942:\tlearn: 0.1341338\ttotal: 11m 44s\tremaining: 35.9s\n",
      "943:\tlearn: 0.1341223\ttotal: 11m 45s\tremaining: 35.1s\n",
      "944:\tlearn: 0.1341068\ttotal: 11m 46s\tremaining: 34.4s\n",
      "945:\tlearn: 0.1340883\ttotal: 11m 46s\tremaining: 33.6s\n",
      "946:\tlearn: 0.1340693\ttotal: 11m 47s\tremaining: 32.9s\n",
      "947:\tlearn: 0.1340689\ttotal: 11m 48s\tremaining: 32.1s\n",
      "948:\tlearn: 0.1340405\ttotal: 11m 48s\tremaining: 31.4s\n",
      "949:\tlearn: 0.1340224\ttotal: 11m 49s\tremaining: 30.6s\n",
      "950:\tlearn: 0.1339959\ttotal: 11m 50s\tremaining: 29.9s\n",
      "951:\tlearn: 0.1339799\ttotal: 11m 50s\tremaining: 29.1s\n",
      "952:\tlearn: 0.1339660\ttotal: 11m 51s\tremaining: 28.4s\n",
      "953:\tlearn: 0.1339613\ttotal: 11m 52s\tremaining: 27.6s\n",
      "954:\tlearn: 0.1339566\ttotal: 11m 52s\tremaining: 26.9s\n",
      "955:\tlearn: 0.1339349\ttotal: 11m 53s\tremaining: 26.1s\n",
      "956:\tlearn: 0.1339156\ttotal: 11m 54s\tremaining: 25.4s\n",
      "957:\tlearn: 0.1339066\ttotal: 11m 54s\tremaining: 24.6s\n",
      "958:\tlearn: 0.1338834\ttotal: 11m 55s\tremaining: 23.9s\n",
      "959:\tlearn: 0.1338821\ttotal: 11m 56s\tremaining: 23.1s\n",
      "960:\tlearn: 0.1338766\ttotal: 11m 56s\tremaining: 22.4s\n",
      "961:\tlearn: 0.1338518\ttotal: 11m 57s\tremaining: 21.6s\n",
      "962:\tlearn: 0.1338468\ttotal: 11m 58s\tremaining: 20.9s\n",
      "963:\tlearn: 0.1338380\ttotal: 11m 59s\tremaining: 20.1s\n",
      "964:\tlearn: 0.1338118\ttotal: 11m 59s\tremaining: 19.4s\n",
      "965:\tlearn: 0.1338102\ttotal: 12m\tremaining: 18.6s\n",
      "966:\tlearn: 0.1337980\ttotal: 12m\tremaining: 17.9s\n",
      "967:\tlearn: 0.1337877\ttotal: 12m 1s\tremaining: 17.1s\n",
      "968:\tlearn: 0.1337717\ttotal: 12m 2s\tremaining: 16.4s\n",
      "969:\tlearn: 0.1337713\ttotal: 12m 3s\tremaining: 15.7s\n",
      "970:\tlearn: 0.1337475\ttotal: 12m 4s\tremaining: 14.9s\n",
      "971:\tlearn: 0.1337216\ttotal: 12m 4s\tremaining: 14.2s\n",
      "972:\tlearn: 0.1337191\ttotal: 12m 5s\tremaining: 13.4s\n",
      "973:\tlearn: 0.1337101\ttotal: 12m 6s\tremaining: 12.7s\n",
      "974:\tlearn: 0.1337048\ttotal: 12m 7s\tremaining: 11.9s\n",
      "975:\tlearn: 0.1336982\ttotal: 12m 7s\tremaining: 11.2s\n",
      "976:\tlearn: 0.1336811\ttotal: 12m 8s\tremaining: 10.4s\n",
      "977:\tlearn: 0.1336796\ttotal: 12m 9s\tremaining: 9.69s\n",
      "978:\tlearn: 0.1336654\ttotal: 12m 9s\tremaining: 8.94s\n",
      "979:\tlearn: 0.1336514\ttotal: 12m 10s\tremaining: 8.2s\n",
      "980:\tlearn: 0.1336322\ttotal: 12m 11s\tremaining: 7.45s\n",
      "981:\tlearn: 0.1336082\ttotal: 12m 11s\tremaining: 6.71s\n",
      "982:\tlearn: 0.1335838\ttotal: 12m 12s\tremaining: 5.96s\n",
      "983:\tlearn: 0.1335651\ttotal: 12m 13s\tremaining: 5.22s\n",
      "984:\tlearn: 0.1335626\ttotal: 12m 14s\tremaining: 4.47s\n",
      "985:\tlearn: 0.1335370\ttotal: 12m 14s\tremaining: 3.73s\n",
      "986:\tlearn: 0.1335247\ttotal: 12m 15s\tremaining: 2.98s\n",
      "987:\tlearn: 0.1335154\ttotal: 12m 16s\tremaining: 2.23s\n",
      "988:\tlearn: 0.1334926\ttotal: 12m 16s\tremaining: 1.49s\n",
      "989:\tlearn: 0.1334886\ttotal: 12m 17s\tremaining: 745ms\n",
      "990:\tlearn: 0.1334813\ttotal: 12m 18s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x23da20ec920>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_days_enc = CatBoostClassifier(**best_params, cat_features=categorical_features_names)\n",
    "\n",
    "cat_days_enc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b63b75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"AUC\",\n",
    "        \"verbose\": 0,\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.5),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 0.01, 10.0),\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.01, 1.0),\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(x_train, y_train):\n",
    "        X_train_cv, X_valid_cv = x_train.iloc[train_idx], x_train.iloc[valid_idx]\n",
    "        y_train_cv, y_valid_cv = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "        model = CatBoostClassifier(**params, cat_features=categorical_features_names)\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        preds = model.predict_proba(X_valid_cv)[:, 1]\n",
    "        auc = roc_auc_score(y_valid_cv, preds)\n",
    "        aucs.append(auc)\n",
    "\n",
    "    return np.mean(aucs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "358bff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 13:00:55,740] A new study created in memory with name: no-name-e9225a92-3533-46ec-b2ed-4ba0758678b9\n",
      "[I 2025-08-07 13:08:45,803] Trial 0 finished with value: 0.9643599492789072 and parameters: {'depth': 5, 'learning_rate': 0.3416027149777706, 'l2_leaf_reg': 3.8428687859685704, 'iterations': 820, 'subsample': 0.6102492740395965}. Best is trial 0 with value: 0.9643599492789072.\n",
      "[I 2025-08-07 13:21:24,313] Trial 1 finished with value: 0.9647696536219931 and parameters: {'depth': 7, 'learning_rate': 0.18500813401248692, 'l2_leaf_reg': 6.109561641503863, 'iterations': 894, 'subsample': 0.8921725091559454}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 13:32:29,375] Trial 2 finished with value: 0.9645268762061188 and parameters: {'depth': 6, 'learning_rate': 0.24793828703984758, 'l2_leaf_reg': 1.3273785944319036, 'iterations': 908, 'subsample': 0.9112405823410208}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 13:47:02,650] Trial 3 finished with value: 0.9592606179019743 and parameters: {'depth': 9, 'learning_rate': 0.44809855977011803, 'l2_leaf_reg': 7.1872803484024095, 'iterations': 936, 'subsample': 0.3637542806912538}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 13:57:13,372] Trial 4 finished with value: 0.9642157652950336 and parameters: {'depth': 6, 'learning_rate': 0.08283363493140633, 'l2_leaf_reg': 7.434586134258043, 'iterations': 969, 'subsample': 0.5530476580083996}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 13:59:45,447] Trial 5 finished with value: 0.9604631863520501 and parameters: {'depth': 2, 'learning_rate': 0.2298770343035761, 'l2_leaf_reg': 5.145963560970693, 'iterations': 610, 'subsample': 0.6659545277838089}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 14:12:00,126] Trial 6 finished with value: 0.9644468409098166 and parameters: {'depth': 10, 'learning_rate': 0.06389711398460035, 'l2_leaf_reg': 7.9491476313211145, 'iterations': 642, 'subsample': 0.42861826088063487}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 14:20:16,486] Trial 7 finished with value: 0.9641512558260599 and parameters: {'depth': 6, 'learning_rate': 0.09360601049121119, 'l2_leaf_reg': 6.949824292658751, 'iterations': 836, 'subsample': 0.32944954790463254}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 14:23:09,805] Trial 8 finished with value: 0.9624813581244598 and parameters: {'depth': 3, 'learning_rate': 0.28672452673269855, 'l2_leaf_reg': 6.884664771139933, 'iterations': 514, 'subsample': 0.35701720585049573}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 14:23:57,727] Trial 9 finished with value: 0.949860677059764 and parameters: {'depth': 1, 'learning_rate': 0.29281810785794093, 'l2_leaf_reg': 3.411657865815366, 'iterations': 221, 'subsample': 0.9062062639295432}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 14:28:21,733] Trial 10 finished with value: 0.9639336353578689 and parameters: {'depth': 8, 'learning_rate': 0.16394753174219995, 'l2_leaf_reg': 9.954827858267516, 'iterations': 365, 'subsample': 0.16419552476700933}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 14:39:28,928] Trial 11 finished with value: 0.9642006447587381 and parameters: {'depth': 7, 'learning_rate': 0.1830585318246113, 'l2_leaf_reg': 0.1834220436757914, 'iterations': 755, 'subsample': 0.9854130275431882}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 14:47:34,183] Trial 12 finished with value: 0.964142681696508 and parameters: {'depth': 4, 'learning_rate': 0.3969189804678592, 'l2_leaf_reg': 0.44720747326614596, 'iterations': 977, 'subsample': 0.8229730926999252}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 14:58:44,184] Trial 13 finished with value: 0.9597164772925293 and parameters: {'depth': 8, 'learning_rate': 0.007367468831264157, 'l2_leaf_reg': 2.100317673418734, 'iterations': 747, 'subsample': 0.7723307964878721}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 15:03:01,870] Trial 14 finished with value: 0.9635903309745002 and parameters: {'depth': 5, 'learning_rate': 0.19584446191352117, 'l2_leaf_reg': 5.208442650403577, 'iterations': 444, 'subsample': 0.7567299922639423}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 15:15:28,559] Trial 15 finished with value: 0.9630973413821415 and parameters: {'depth': 7, 'learning_rate': 0.3335999014691967, 'l2_leaf_reg': 1.5984235273197003, 'iterations': 862, 'subsample': 0.9731177468964356}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 15:19:51,616] Trial 16 finished with value: 0.9600323012764944 and parameters: {'depth': 4, 'learning_rate': 0.12415844036759245, 'l2_leaf_reg': 3.93836532622099, 'iterations': 691, 'subsample': 0.014155746484338372}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 15:21:25,716] Trial 17 finished with value: 0.962647728280513 and parameters: {'depth': 7, 'learning_rate': 0.25235362825705554, 'l2_leaf_reg': 5.693819727651605, 'iterations': 174, 'subsample': 0.8676271747041665}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 15:41:03,902] Trial 18 finished with value: 0.9640624724921198 and parameters: {'depth': 10, 'learning_rate': 0.14853616438833644, 'l2_leaf_reg': 8.805923466908983, 'iterations': 879, 'subsample': 0.6533173041060794}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 15:45:56,695] Trial 19 finished with value: 0.9620236456809395 and parameters: {'depth': 8, 'learning_rate': 0.48606119997745123, 'l2_leaf_reg': 2.7243748974673023, 'iterations': 308, 'subsample': 0.7462385858098466}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 15:52:01,762] Trial 20 finished with value: 0.9640621940115551 and parameters: {'depth': 4, 'learning_rate': 0.24166533749430316, 'l2_leaf_reg': 6.0522844239649665, 'iterations': 742, 'subsample': 0.8997689251842607}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 16:04:09,630] Trial 21 finished with value: 0.963976490562149 and parameters: {'depth': 10, 'learning_rate': 0.03720263115388314, 'l2_leaf_reg': 8.643231665835561, 'iterations': 623, 'subsample': 0.457367848672599}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 16:14:21,889] Trial 22 finished with value: 0.9644301798595449 and parameters: {'depth': 9, 'learning_rate': 0.0640463951603153, 'l2_leaf_reg': 8.209812207156888, 'iterations': 650, 'subsample': 0.499293005289847}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 16:21:45,891] Trial 23 finished with value: 0.9644021713235557 and parameters: {'depth': 9, 'learning_rate': 0.12555744002018573, 'l2_leaf_reg': 9.851872486775195, 'iterations': 520, 'subsample': 0.2516581857576109}. Best is trial 1 with value: 0.9647696536219931.\n",
      "[I 2025-08-07 16:32:12,077] Trial 24 finished with value: 0.9648380349372317 and parameters: {'depth': 6, 'learning_rate': 0.19534899762876842, 'l2_leaf_reg': 6.289926032296311, 'iterations': 923, 'subsample': 0.6980479541056628}. Best is trial 24 with value: 0.9648380349372317.\n",
      "[I 2025-08-07 16:42:41,268] Trial 25 finished with value: 0.9648090519837856 and parameters: {'depth': 6, 'learning_rate': 0.18661837374503812, 'l2_leaf_reg': 4.457133883288858, 'iterations': 896, 'subsample': 0.835619924794647}. Best is trial 24 with value: 0.9648380349372317.\n",
      "[I 2025-08-07 16:50:27,642] Trial 26 finished with value: 0.9644707068471582 and parameters: {'depth': 5, 'learning_rate': 0.20410858147890507, 'l2_leaf_reg': 4.597152161737239, 'iterations': 788, 'subsample': 0.7097657428693992}. Best is trial 24 with value: 0.9648380349372317.\n",
      "[I 2025-08-07 17:04:30,913] Trial 27 finished with value: 0.9648799215900337 and parameters: {'depth': 7, 'learning_rate': 0.1280757041376676, 'l2_leaf_reg': 6.136480654445323, 'iterations': 993, 'subsample': 0.811156485633777}. Best is trial 27 with value: 0.9648799215900337.\n",
      "[I 2025-08-07 17:18:48,098] Trial 28 finished with value: 0.9647515849969477 and parameters: {'depth': 6, 'learning_rate': 0.11990753106597866, 'l2_leaf_reg': 4.667453469961297, 'iterations': 987, 'subsample': 0.8167338405623646}. Best is trial 27 with value: 0.9648799215900337.\n",
      "[I 2025-08-07 17:28:18,037] Trial 29 finished with value: 0.9644433662008348 and parameters: {'depth': 5, 'learning_rate': 0.2831598991513574, 'l2_leaf_reg': 3.9953216594271765, 'iterations': 833, 'subsample': 0.5864265411584484}. Best is trial 27 with value: 0.9648799215900337.\n",
      "[I 2025-08-07 17:36:02,349] Trial 30 finished with value: 0.9631423474376704 and parameters: {'depth': 3, 'learning_rate': 0.21345306193266333, 'l2_leaf_reg': 6.345854372025172, 'iterations': 930, 'subsample': 0.6560954269983802}. Best is trial 27 with value: 0.9648799215900337.\n",
      "[W 2025-08-07 17:44:40,771] Trial 31 failed with parameters: {'depth': 7, 'learning_rate': 0.16209011973523665, 'l2_leaf_reg': 5.738041693309223, 'iterations': 891, 'subsample': 0.825062369998983} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\olive\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_12096\\3964674104.py\", line 26, in objective\n",
      "    model.fit(X_train_cv, y_train_cv)\n",
      "  File \"c:\\Users\\olive\\miniconda3\\Lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Users\\olive\\miniconda3\\Lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\olive\\miniconda3\\Lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-07 17:44:40,955] Trial 31 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\n\u001b[32m      3\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest AUC:\u001b[39m\u001b[33m\"\u001b[39m, study.best_value)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest Params:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olive\\miniconda3\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olive\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olive\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olive\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olive\\miniconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     23\u001b[39m y_train_cv, y_valid_cv = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n\u001b[32m     25\u001b[39m model = CatBoostClassifier(**params, cat_features=categorical_features_names)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m preds = model.predict_proba(X_valid_cv)[:, \u001b[32m1\u001b[39m]\n\u001b[32m     29\u001b[39m auc = roc_auc_score(y_valid_cv, preds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olive\\miniconda3\\Lib\\site-packages\\catboost\\core.py:5245\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5243\u001b[39m     CatBoostClassifier._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5245\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5246\u001b[39m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5247\u001b[39m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olive\\miniconda3\\Lib\\site-packages\\catboost\\core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olive\\miniconda3\\Lib\\site-packages\\catboost\\core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=40)\n",
    "\n",
    "print(\"Best AUC:\", study.best_value)\n",
    "print(\"Best Params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e818b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28922ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_best_model = CatBoostClassifier(**study.best_params, cat_features=categorical_features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756eb8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Your existing Optuna code\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=40)\n",
    "\n",
    "print(\"Best Params:\", study.best_params)\n",
    "\n",
    "# Save the best parameters to a JSON file\n",
    "with open(\"models/optuna_cat2_targetenc.json\", \"w\") as f:\n",
    "    json.dump(study.best_params, f, indent=4)\n",
    "\n",
    "print(\"Best parameters saved to 'best_params.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e496ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
